{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLAGS (IMPORTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATE_NN = True\n",
    "TRAIN = True\n",
    "VALIDATE_SVM = True\n",
    "\n",
    "# change code to use these flags and do the action otherwise load necessary stuff already saved\n",
    "# also update docstrings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGH_COUNT = 100\n",
    "LOW_FRAC = 1/64\n",
    "ZERO_FRAC = 0.5\n",
    "TEST_COUNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTRE = 4 * torch.ones(7)\n",
    "CENTRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW_RADIUS = 1.\n",
    "HIGH_RADIUS = 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data.orthants import generate_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, Y_training, orthant_counts = generate_train_data(\n",
    "    low_count=HIGH_COUNT,\n",
    "    high_count=HIGH_COUNT,\n",
    "    low_spread=0,\n",
    "    high_spread=0,\n",
    "    low_frac=LOW_FRAC,\n",
    "    zero_frac=ZERO_FRAC,\n",
    "    random_state=7357\n",
    ")\n",
    "X_training.shape, Y_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(128):\n",
    "    if orthant_counts[i] == 0:\n",
    "        ZERO_ORTHANT_INDEX = i\n",
    "ZERO_ORTHANT_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_training, Y_training, test_size=0.2, random_state=535)\n",
    "X_train.shape, X_val.shape, Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data.orthants import generate_test_data\n",
    "\n",
    "X_test, Y_test = generate_test_data(TEST_COUNT, random_state=7753)\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import make_dataloader\n",
    "\n",
    "train_dataloader, val_dataloader = make_dataloader(X_train, Y_train, 32, True), make_dataloader(X_val, Y_val, 32, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total_0 = X_training[Y_training.squeeze()==0]\n",
    "X_total_1 = X_training[Y_training.squeeze()==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data.orthants import find_orthant\n",
    "\n",
    "def obtain_closest_point_orthant(\n",
    "    test_point: torch.Tensor,\n",
    "    pos_points: torch.Tensor,\n",
    "    neg_points: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    pos_distances, neg_distances = torch.sqrt(torch.sum((test_point - pos_points)**2, dim=1)), torch.sqrt(torch.sum((test_point - neg_points)**2, dim=1))\n",
    "    return torch.tensor([find_orthant(pos_points[torch.argmin(pos_distances)]), find_orthant(neg_points[torch.argmin(neg_distances)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "closest_orthants_0 = pd.DataFrame(torch.cat([\n",
    "    obtain_closest_point_orthant(x, X_total_0, X_total_1).reshape(1, -1) for x in X_test[ZERO_ORTHANT_INDEX][Y_test[ZERO_ORTHANT_INDEX].squeeze() == 0]\n",
    "]), columns=['closest_positive_orthant', 'closest_negative_orthant'])\n",
    "closest_orthants_1 = pd.DataFrame(torch.cat([\n",
    "    obtain_closest_point_orthant(x, X_total_0, X_total_1).reshape(1, -1) for x in X_test[ZERO_ORTHANT_INDEX][Y_test[ZERO_ORTHANT_INDEX].squeeze() == 1]\n",
    "]), columns=['closest_positive_orthant', 'closest_negative_orthant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_orthants_0['closest_positive_orthant'].value_counts(), closest_orthants_0['closest_negative_orthant'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_orthants_1['closest_positive_orthant'].value_counts(), closest_orthants_1['closest_negative_orthant'].value_counts() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models import SimpleNN\n",
    "from scripts.train import train_model\n",
    "from scripts.metrics import BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1, 2, 3, 4, 5]\n",
    "widths = [32, 64, 128]\n",
    "etas = [1e-4, 1e-3, 1e-2]\n",
    "weight_decays = np.logspace(-5, 5, 11).tolist() \n",
    "weight_decays.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if VALIDATE_NN:\n",
    "    best_depth = None\n",
    "    best_width = None\n",
    "    best_eta = None\n",
    "    best_weight_decay = None\n",
    "    best_score = -torch.inf\n",
    "else:\n",
    "    with open('configs/nn/orthants-single-empty.json', 'r') as f:\n",
    "        best_config = json.load(f)\n",
    "    best_depth = best_config['depth']\n",
    "    best_width = best_config['width']\n",
    "    best_eta = best_config['eta']\n",
    "    best_weight_decay = best_config['weight_decay']\n",
    "    best_score = best_config['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "total_count = len(depths) * len(widths) * len(etas) * len(weight_decays)\n",
    "curr_count = 0\n",
    "EPOCHS = 10\n",
    "\n",
    "if VALIDATE_NN:\n",
    "    print(f'Cross-validating across {total_count} models.\\n')\n",
    "\n",
    "    for depth in depths:\n",
    "        for width in widths:\n",
    "            for eta in etas:\n",
    "                for weight_decay in weight_decays:\n",
    "                    model = SimpleNN(7, hidden_layers=depth, hidden_units=width).to(device)\n",
    "                    loss_fn = torch.nn.BCELoss()\n",
    "                    optimizer = torch.optim.Adam(params=model.parameters(), lr=eta, weight_decay=weight_decay)\n",
    "                    metric = BinaryAccuracy()\n",
    "\n",
    "                    history = train_model(\n",
    "                        model=model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader,\n",
    "                        loss_fn=loss_fn,\n",
    "                        optimizer=optimizer,\n",
    "                        metric=metric,\n",
    "                        epochs=EPOCHS,\n",
    "                        verbose=0,\n",
    "                        device=device\n",
    "                    )\n",
    "                    curr_count += 1\n",
    "                    score = history['val_score'][-1]\n",
    "                    print(f'[{curr_count}/{total_count}] Depth: {depth}, width: {width}, lr: {eta}, lambda: {weight_decay} ==> score: {score:.6f}')\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_depth = depth\n",
    "                        best_width = width\n",
    "                        best_eta = eta\n",
    "                        best_weight_decay = weight_decay\n",
    "    best_config = {\n",
    "        'score': best_score,\n",
    "        'depth': best_depth,\n",
    "        'width': best_width,\n",
    "        'eta': best_eta,\n",
    "        'weight_decay': best_weight_decay\n",
    "    }\n",
    "    with open('configs/nn/orthants-single-empty.json', 'w') as f:\n",
    "        json.dump(best_config, f)\n",
    "\n",
    "print(f'\\nBest validation score after {EPOCHS} epochs: {best_score:.6f}')\n",
    "print(f'Best configuration: depth: {best_depth}, width: {best_width}, lr: {best_eta}, lambda: {best_weight_decay}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_nn = SimpleNN(7, hidden_layers=best_depth, hidden_units=best_width).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import EarlyStopping\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=best_model_nn.parameters(), lr=best_eta, weight_decay=best_weight_decay)\n",
    "metric = BinaryAccuracy()\n",
    "early_stop = EarlyStopping(patience=20, min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    history = train_model(\n",
    "        model=best_model_nn,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        metric=metric,\n",
    "        epochs=500,\n",
    "        early_stopping=early_stop,\n",
    "        device=device,\n",
    "        return_models=True\n",
    "    )\n",
    "    torch.save(best_model_nn.state_dict(), 'models/orthants-single-empty.pth')\n",
    "else:\n",
    "    best_model_nn.load_state_dict(torch.load('models/orthants-single-empty.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import plot_train_history\n",
    "\n",
    "if TRAIN:\n",
    "    plot_train_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import plot_radial_visualization\n",
    "\n",
    "if TRAIN:\n",
    "    plot_radial_visualization(\n",
    "        models=history['models'],\n",
    "        mp4_save_file_name='radial_1empty',\n",
    "        orthant_counts=orthant_counts,\n",
    "        main_orthant=ZERO_ORTHANT_INDEX,\n",
    "        fps=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.test import predict\n",
    "\n",
    "scores_nn = torch.tensor([\n",
    "    metric(\n",
    "        predict(best_model_nn, X_test[i], device),\n",
    "        Y_test[i]\n",
    "    ) for i in range(128)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nn.mean(), scores_nn[ZERO_ORTHANT_INDEX].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from scripts.ntk import NTK\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntk = NTK(best_model_nn).get_ntk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_ntk = SVC(kernel=ntk, max_iter=int(1e4))\n",
    "params_ntk = {\n",
    "    'C': np.logspace(-5, 5, 11)\n",
    "}\n",
    "\n",
    "gammas = np.logspace(-5, 5, 11).tolist()\n",
    "gammas.append('scale')\n",
    "gammas.append('auto')\n",
    "model_base_rbf = SVC(kernel='rbf', max_iter=int(1e4))\n",
    "params_rbf = {\n",
    "    'C': np.logspace(-5, 5, 11),\n",
    "    'gamma': gammas\n",
    "}\n",
    "\n",
    "scorer = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VALIDATE_SVM:\n",
    "    model_cv_ntk = GridSearchCV(\n",
    "        estimator=model_base_ntk,\n",
    "        param_grid=params_ntk,\n",
    "        scoring=scorer,\n",
    "        n_jobs=5,\n",
    "        refit=False,\n",
    "        verbose=3\n",
    "    )\n",
    "    model_cv_ntk.fit(X_train, Y_train.squeeze())\n",
    "    best_params_ntk = model_cv_ntk.best_params_\n",
    "    best_score_ntk = max(model_cv_ntk.cv_results_['mean_test_score'])\n",
    "    best_params_ntk, best_score_ntk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VALIDATE_SVM:\n",
    "    model_cv_rbf = GridSearchCV(\n",
    "        estimator=model_base_rbf,\n",
    "        param_grid=params_rbf,\n",
    "        scoring=scorer,\n",
    "        n_jobs=5,\n",
    "        refit=False,\n",
    "        verbose=3\n",
    "    )\n",
    "    model_cv_rbf.fit(X_train, Y_train.squeeze())\n",
    "    best_params_rbf = model_cv_rbf.best_params_\n",
    "    best_score_rbf = max(model_cv_rbf.cv_results_['mean_test_score'])\n",
    "    best_params_rbf, best_score_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if VALIDATE_SVM:\n",
    "    if best_score_rbf >= best_score_ntk:\n",
    "        best_model_km = SVC(C=best_params_rbf['C'], kernel='rbf', gamma=best_params_rbf['gamma'])\n",
    "        best_config = {\n",
    "            'kernel': 'rbf',\n",
    "            'C': best_params_rbf['C'],\n",
    "            'gamma': best_params_rbf['gamma']\n",
    "        }\n",
    "        with open('configs/svm/orthants-single-empty.json', 'w') as f:\n",
    "            json.dump(best_config, f)\n",
    "    else:\n",
    "        best_model_km = SVC(C=best_params_ntk['C'], kernel=ntk)\n",
    "        best_config = {\n",
    "            'kernel': 'ntk',\n",
    "            'C': best_params_ntk['C']\n",
    "        }\n",
    "        with open('configs/svm/orthants-single-empty.json', 'w') as f:\n",
    "            json.dump(best_config, f)\n",
    "else:\n",
    "    with open('configs/svm/orthants-single-empty.json', 'r') as f:\n",
    "        best_config = json.load(f)\n",
    "    if best_config['kernel'] == 'rbf':\n",
    "        best_model_km = SVC(C=best_config['C'], gamma=best_config['gamma'])\n",
    "    else:\n",
    "        best_model_km = SVC(kernel=ntk, C=best_config['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_km.fit(X_train, Y_train.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train, preds_val = best_model_km.predict(X_train), best_model_km.predict(X_val)\n",
    "score_train, score_val = accuracy_score(Y_train.squeeze(), preds_train), accuracy_score(Y_val.squeeze(), preds_val)\n",
    "score_train, score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_km = np.array([\n",
    "    accuracy_score(\n",
    "        best_model_km.predict(X_test[i]),\n",
    "        Y_test[i].squeeze()\n",
    "    ) for i in range(128)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_km.mean(), scores_km[ZERO_ORTHANT_INDEX].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN vs SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(orthant_counts, scores_nn)\n",
    "plt.xlabel('Number of points')\n",
    "plt.ylabel('Binary accuracy')\n",
    "plt.ylim((0., 1.))\n",
    "plt.title('NN')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(orthant_counts, scores_km)\n",
    "plt.xlabel('Number of points')\n",
    "plt.ylabel('Binary accuracy')\n",
    "plt.ylim((0., 1.))\n",
    "plt.title('SVM')\n",
    "\n",
    "plt.suptitle('Accuracy per orthant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
