X.shape == torch.Size([10000, 100])
scale_factor == 0.004732361529022455
Y.shape == torch.Size([10000, 1])
X_train.shape == torch.Size([8000, 100]), Y_train.shape == torch.Size([8000, 1])
X_val.shape == torch.Size([1000, 100]), Y_val.shape == torch.Size([1000, 1])
X_test.shape == torch.Size([1000, 100]), Y_test.shape == torch.Size([1000, 1])
Cross-validating across 128 models.
[1/128]	Width:128, lr:0.001, w_d:0.0001 => Score:-0.078071
[2/128]	Width:128, lr:0.001, w_d:0.001 => Score:-0.078076
[3/128]	Width:128, lr:0.001, w_d:0.01 => Score:-0.078133
[4/128]	Width:128, lr:0.001, w_d:0.1 => Score:-0.078853
[5/128]	Width:128, lr:0.001, w_d:1.0 => Score:-0.082347
[6/128]	Width:128, lr:0.001, w_d:10.0 => Score:-0.079701
[7/128]	Width:128, lr:0.001, w_d:100.0 => Score:-0.077315
[8/128]	Width:128, lr:0.001, w_d:0.0 => Score:-0.078070
[9/128]	Width:128, lr:0.01, w_d:0.0001 => Score:-0.075560
[10/128]	Width:128, lr:0.01, w_d:0.001 => Score:-0.075565
[11/128]	Width:128, lr:0.01, w_d:0.01 => Score:-0.075611
[12/128]	Width:128, lr:0.01, w_d:0.1 => Score:-0.076677
[13/128]	Width:128, lr:0.01, w_d:1.0 => Score:-0.076069
[14/128]	Width:128, lr:0.01, w_d:10.0 => Score:-0.075697
[15/128]	Width:128, lr:0.01, w_d:100.0 => Score:-0.075717
[16/128]	Width:128, lr:0.01, w_d:0.0 => Score:-0.075560
[17/128]	Width:128, lr:0.1, w_d:0.0001 => Score:-0.075511
[18/128]	Width:128, lr:0.1, w_d:0.001 => Score:-0.075586
[19/128]	Width:128, lr:0.1, w_d:0.01 => Score:-0.075667
[20/128]	Width:128, lr:0.1, w_d:0.1 => Score:-0.075603
[21/128]	Width:128, lr:0.1, w_d:1.0 => Score:-0.075632
[22/128]	Width:128, lr:0.1, w_d:10.0 => Score:-0.075705
[23/128]	Width:128, lr:0.1, w_d:100.0 => Score:-0.075730
[24/128]	Width:128, lr:0.1, w_d:0.0 => Score:-0.075490
[25/128]	Width:128, lr:1.0, w_d:0.0001 => Score:-0.059617
[26/128]	Width:128, lr:1.0, w_d:0.001 => Score:-0.075678
[27/128]	Width:128, lr:1.0, w_d:0.01 => Score:-0.075676
[28/128]	Width:128, lr:1.0, w_d:0.1 => Score:-0.075680
[29/128]	Width:128, lr:1.0, w_d:1.0 => Score:-0.075698
[30/128]	Width:128, lr:1.0, w_d:10.0 => Score:-0.075738
[31/128]	Width:128, lr:1.0, w_d:100.0 => Score:-0.075626
[32/128]	Width:128, lr:1.0, w_d:0.0 => Score:-0.070353
[33/128]	Width:256, lr:0.001, w_d:0.0001 => Score:-0.076317
[34/128]	Width:256, lr:0.001, w_d:0.001 => Score:-0.076319
[35/128]	Width:256, lr:0.001, w_d:0.01 => Score:-0.076340
[36/128]	Width:256, lr:0.001, w_d:0.1 => Score:-0.076606
[37/128]	Width:256, lr:0.001, w_d:1.0 => Score:-0.077687
[38/128]	Width:256, lr:0.001, w_d:10.0 => Score:-0.076982
[39/128]	Width:256, lr:0.001, w_d:100.0 => Score:-0.076156
[40/128]	Width:256, lr:0.001, w_d:0.0 => Score:-0.076317
[41/128]	Width:256, lr:0.01, w_d:0.0001 => Score:-0.075942
[42/128]	Width:256, lr:0.01, w_d:0.001 => Score:-0.075945
[43/128]	Width:256, lr:0.01, w_d:0.01 => Score:-0.075958
[44/128]	Width:256, lr:0.01, w_d:0.1 => Score:-0.076410
[45/128]	Width:256, lr:0.01, w_d:1.0 => Score:-0.076108
[46/128]	Width:256, lr:0.01, w_d:10.0 => Score:-0.076070
[47/128]	Width:256, lr:0.01, w_d:100.0 => Score:-0.076092
[48/128]	Width:256, lr:0.01, w_d:0.0 => Score:-0.075943
[49/128]	Width:256, lr:0.1, w_d:0.0001 => Score:-0.075885
[50/128]	Width:256, lr:0.1, w_d:0.001 => Score:-0.075895
[51/128]	Width:256, lr:0.1, w_d:0.01 => Score:-0.075986
[52/128]	Width:256, lr:0.1, w_d:0.1 => Score:-0.075961
[53/128]	Width:256, lr:0.1, w_d:1.0 => Score:-0.075992
[54/128]	Width:256, lr:0.1, w_d:10.0 => Score:-0.076059
[55/128]	Width:256, lr:0.1, w_d:100.0 => Score:-0.076096
[56/128]	Width:256, lr:0.1, w_d:0.0 => Score:-0.075886
[57/128]	Width:256, lr:1.0, w_d:0.0001 => Score:-0.061173
[58/128]	Width:256, lr:1.0, w_d:0.001 => Score:-0.077999
[59/128]	Width:256, lr:1.0, w_d:0.01 => Score:-0.075919
[60/128]	Width:256, lr:1.0, w_d:0.1 => Score:-0.075929
[61/128]	Width:256, lr:1.0, w_d:1.0 => Score:-0.075969
[62/128]	Width:256, lr:1.0, w_d:10.0 => Score:-0.079306
[63/128]	Width:256, lr:1.0, w_d:100.0 => Score:-0.094818
[64/128]	Width:256, lr:1.0, w_d:0.0 => Score:-0.065801
[65/128]	Width:512, lr:0.001, w_d:0.0001 => Score:-0.076069
[66/128]	Width:512, lr:0.001, w_d:0.001 => Score:-0.076069
[67/128]	Width:512, lr:0.001, w_d:0.01 => Score:-0.076069
[68/128]	Width:512, lr:0.001, w_d:0.1 => Score:-0.076067
[69/128]	Width:512, lr:0.001, w_d:1.0 => Score:-0.076073
[70/128]	Width:512, lr:0.001, w_d:10.0 => Score:-0.076108
[71/128]	Width:512, lr:0.001, w_d:100.0 => Score:-0.076163
[72/128]	Width:512, lr:0.001, w_d:0.0 => Score:-0.076069
[73/128]	Width:512, lr:0.01, w_d:0.0001 => Score:-0.076087
[74/128]	Width:512, lr:0.01, w_d:0.001 => Score:-0.076087
[75/128]	Width:512, lr:0.01, w_d:0.01 => Score:-0.076086
[76/128]	Width:512, lr:0.01, w_d:0.1 => Score:-0.076079
[77/128]	Width:512, lr:0.01, w_d:1.0 => Score:-0.076098
[78/128]	Width:512, lr:0.01, w_d:10.0 => Score:-0.076148
[79/128]	Width:512, lr:0.01, w_d:100.0 => Score:-0.076165
[80/128]	Width:512, lr:0.01, w_d:0.0 => Score:-0.076086
[81/128]	Width:512, lr:0.1, w_d:0.0001 => Score:-0.076069
[82/128]	Width:512, lr:0.1, w_d:0.001 => Score:-0.076163
[83/128]	Width:512, lr:0.1, w_d:0.01 => Score:-0.076086
[84/128]	Width:512, lr:0.1, w_d:0.1 => Score:-0.076087
[85/128]	Width:512, lr:0.1, w_d:1.0 => Score:-0.076109
[86/128]	Width:512, lr:0.1, w_d:10.0 => Score:-0.076171
[87/128]	Width:512, lr:0.1, w_d:100.0 => Score:-0.076177
[88/128]	Width:512, lr:0.1, w_d:0.0 => Score:-0.076039
[89/128]	Width:512, lr:1.0, w_d:0.0001 => Score:-0.064785
[90/128]	Width:512, lr:1.0, w_d:0.001 => Score:-0.077854
[91/128]	Width:512, lr:1.0, w_d:0.01 => Score:-0.076288
[92/128]	Width:512, lr:1.0, w_d:0.1 => Score:-0.076288
[93/128]	Width:512, lr:1.0, w_d:1.0 => Score:-0.076283
[94/128]	Width:512, lr:1.0, w_d:10.0 => Score:-0.081700
[95/128]	Width:512, lr:1.0, w_d:100.0 => Score:-0.090534
[96/128]	Width:512, lr:1.0, w_d:0.0 => Score:-0.071662
[97/128]	Width:1024, lr:0.001, w_d:0.0001 => Score:-0.086560
[98/128]	Width:1024, lr:0.001, w_d:0.001 => Score:-0.086560
[99/128]	Width:1024, lr:0.001, w_d:0.01 => Score:-0.086560
[100/128]	Width:1024, lr:0.001, w_d:0.1 => Score:-0.086567
[101/128]	Width:1024, lr:0.001, w_d:1.0 => Score:-0.086686
[102/128]	Width:1024, lr:0.001, w_d:10.0 => Score:-0.086691
[103/128]	Width:1024, lr:0.001, w_d:100.0 => Score:-0.086623
[104/128]	Width:1024, lr:0.001, w_d:0.0 => Score:-0.086560
[105/128]	Width:1024, lr:0.01, w_d:0.0001 => Score:-0.086600
[106/128]	Width:1024, lr:0.01, w_d:0.001 => Score:-0.086597
[107/128]	Width:1024, lr:0.01, w_d:0.01 => Score:-0.086580
[108/128]	Width:1024, lr:0.01, w_d:0.1 => Score:-0.086645
[109/128]	Width:1024, lr:0.01, w_d:1.0 => Score:-0.086596
[110/128]	Width:1024, lr:0.01, w_d:10.0 => Score:-0.086611
[111/128]	Width:1024, lr:0.01, w_d:100.0 => Score:-0.086623
[112/128]	Width:1024, lr:0.01, w_d:0.0 => Score:-0.086600
[113/128]	Width:1024, lr:0.1, w_d:0.0001 => Score:-0.086937
[114/128]	Width:1024, lr:0.1, w_d:0.001 => Score:-0.086769
[115/128]	Width:1024, lr:0.1, w_d:0.01 => Score:-0.086567
[116/128]	Width:1024, lr:0.1, w_d:0.1 => Score:-0.086565
[117/128]	Width:1024, lr:0.1, w_d:1.0 => Score:-0.086578
[118/128]	Width:1024, lr:0.1, w_d:10.0 => Score:-0.086616
[119/128]	Width:1024, lr:0.1, w_d:100.0 => Score:-0.086658
[120/128]	Width:1024, lr:0.1, w_d:0.0 => Score:-0.086958
[121/128]	Width:1024, lr:1.0, w_d:0.0001 => Score:-0.100692
[122/128]	Width:1024, lr:1.0, w_d:0.001 => Score:-0.089088
[123/128]	Width:1024, lr:1.0, w_d:0.01 => Score:-0.086597
[124/128]	Width:1024, lr:1.0, w_d:0.1 => Score:-0.086599
[125/128]	Width:1024, lr:1.0, w_d:1.0 => Score:-0.086627
[126/128]	Width:1024, lr:1.0, w_d:10.0 => Score:-0.115363
[127/128]	Width:1024, lr:1.0, w_d:100.0 => Score:-0.160973
[128/128]	Width:1024, lr:1.0, w_d:0.0 => Score:-0.108979

Best validation score after 20 epochs: -0.059617. Best configuration:
Width:128, lr:1.0, w_d:0.0001
preds_train_nn.shape == torch.Size([8000, 1]), preds_val_nn.shape == torch.Size([1000, 1]), preds_test_nn.shape == torch.Size([1000, 1])
score_train == -0.12456698715686798, score_val == -0.04646151140332222, score_test == -0.040733810514211655
Best params for NTK: {'C': 0.1}
Best score for NTK: -0.11582642168554003
Best params for RBF: {'C': 100.0, 'gamma': 'scale'}
Best score for RBF: -0.07748354810322458
Best kernel: rbf
preds_train_km.shape == (8000,), preds_val_km.shape == (1000,), preds_test_km.shape == (1000,)
score_train == 0.004397333375935771, score_val == 0.02131784982982067, score_test == 0.02024082633923485
