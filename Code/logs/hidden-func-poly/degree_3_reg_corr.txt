X.shape == torch.Size([10000, 100])
scale_factor == 0.004732361529022455
Y.shape == torch.Size([10000, 1])
X_train.shape == torch.Size([8000, 100]), Y_train.shape == torch.Size([8000, 1])
X_val.shape == torch.Size([1000, 100]), Y_val.shape == torch.Size([1000, 1])
X_test.shape == torch.Size([1000, 100]), Y_test.shape == torch.Size([1000, 1])
Cross-validating across 128 models.
[1/128]	Width:128, lr:0.001, w_d:0.0001 => Score:-2.458419
[2/128]	Width:128, lr:0.001, w_d:0.001 => Score:-2.458453
[3/128]	Width:128, lr:0.001, w_d:0.01 => Score:-2.458785
[4/128]	Width:128, lr:0.001, w_d:0.1 => Score:-2.461532
[5/128]	Width:128, lr:0.001, w_d:1.0 => Score:-2.464113
[6/128]	Width:128, lr:0.001, w_d:10.0 => Score:-2.462880
[7/128]	Width:128, lr:0.001, w_d:100.0 => Score:-2.462916
[8/128]	Width:128, lr:0.001, w_d:0.0 => Score:-2.458416
[9/128]	Width:128, lr:0.01, w_d:0.0001 => Score:-2.322634
[10/128]	Width:128, lr:0.01, w_d:0.001 => Score:-2.329156
[11/128]	Width:128, lr:0.01, w_d:0.01 => Score:-2.381089
[12/128]	Width:128, lr:0.01, w_d:0.1 => Score:-2.463129
[13/128]	Width:128, lr:0.01, w_d:1.0 => Score:-2.462781
[14/128]	Width:128, lr:0.01, w_d:10.0 => Score:-2.464339
[15/128]	Width:128, lr:0.01, w_d:100.0 => Score:-2.464482
[16/128]	Width:128, lr:0.01, w_d:0.0 => Score:-2.321888
[17/128]	Width:128, lr:0.1, w_d:0.0001 => Score:-0.005811
[18/128]	Width:128, lr:0.1, w_d:0.001 => Score:-0.005792
[19/128]	Width:128, lr:0.1, w_d:0.01 => Score:-0.005427
[20/128]	Width:128, lr:0.1, w_d:0.1 => Score:-2.462812
[21/128]	Width:128, lr:0.1, w_d:1.0 => Score:-2.463594
[22/128]	Width:128, lr:0.1, w_d:10.0 => Score:-2.464408
[23/128]	Width:128, lr:0.1, w_d:100.0 => Score:-2.464998
[24/128]	Width:128, lr:0.1, w_d:0.0 => Score:-0.005707
[25/128]	Width:128, lr:1.0, w_d:0.0001 => Score:-0.007090
[26/128]	Width:128, lr:1.0, w_d:0.001 => Score:-0.012883
[27/128]	Width:128, lr:1.0, w_d:0.01 => Score:-0.010041
[28/128]	Width:128, lr:1.0, w_d:0.1 => Score:-2.462954
[29/128]	Width:128, lr:1.0, w_d:1.0 => Score:-2.464027
[30/128]	Width:128, lr:1.0, w_d:10.0 => Score:-2.532259
[31/128]	Width:128, lr:1.0, w_d:100.0 => Score:-2.553016
[32/128]	Width:128, lr:1.0, w_d:0.0 => Score:-0.003456
[33/128]	Width:256, lr:0.001, w_d:0.0001 => Score:-2.468930
[34/128]	Width:256, lr:0.001, w_d:0.001 => Score:-2.469026
[35/128]	Width:256, lr:0.001, w_d:0.01 => Score:-2.469976
[36/128]	Width:256, lr:0.001, w_d:0.1 => Score:-2.477051
[37/128]	Width:256, lr:0.001, w_d:1.0 => Score:-2.485147
[38/128]	Width:256, lr:0.001, w_d:10.0 => Score:-2.486754
[39/128]	Width:256, lr:0.001, w_d:100.0 => Score:-2.488804
[40/128]	Width:256, lr:0.001, w_d:0.0 => Score:-2.468919
[41/128]	Width:256, lr:0.01, w_d:0.0001 => Score:-2.268059
[42/128]	Width:256, lr:0.01, w_d:0.001 => Score:-2.278201
[43/128]	Width:256, lr:0.01, w_d:0.01 => Score:-2.359116
[44/128]	Width:256, lr:0.01, w_d:0.1 => Score:-2.485473
[45/128]	Width:256, lr:0.01, w_d:1.0 => Score:-2.486883
[46/128]	Width:256, lr:0.01, w_d:10.0 => Score:-2.488877
[47/128]	Width:256, lr:0.01, w_d:100.0 => Score:-2.489066
[48/128]	Width:256, lr:0.01, w_d:0.0 => Score:-2.266901
[49/128]	Width:256, lr:0.1, w_d:0.0001 => Score:-0.006238
[50/128]	Width:256, lr:0.1, w_d:0.001 => Score:-0.006406
[51/128]	Width:256, lr:0.1, w_d:0.01 => Score:-0.005890
[52/128]	Width:256, lr:0.1, w_d:0.1 => Score:-2.485851
[53/128]	Width:256, lr:0.1, w_d:1.0 => Score:-2.487629
[54/128]	Width:256, lr:0.1, w_d:10.0 => Score:-2.488786
[55/128]	Width:256, lr:0.1, w_d:100.0 => Score:-2.490541
[56/128]	Width:256, lr:0.1, w_d:0.0 => Score:-0.006401
[57/128]	Width:256, lr:1.0, w_d:0.0001 => Score:-0.005712
[58/128]	Width:256, lr:1.0, w_d:0.001 => Score:-0.012133
[59/128]	Width:256, lr:1.0, w_d:0.01 => Score:-0.008526
[60/128]	Width:256, lr:1.0, w_d:0.1 => Score:-2.485532
[61/128]	Width:256, lr:1.0, w_d:1.0 => Score:-2.487086
[62/128]	Width:256, lr:1.0, w_d:10.0 => Score:-2.625052
[63/128]	Width:256, lr:1.0, w_d:100.0 => Score:-2.720879
[64/128]	Width:256, lr:1.0, w_d:0.0 => Score:-0.007723
[65/128]	Width:512, lr:0.001, w_d:0.0001 => Score:-2.445271
[66/128]	Width:512, lr:0.001, w_d:0.001 => Score:-2.445403
[67/128]	Width:512, lr:0.001, w_d:0.01 => Score:-2.446714
[68/128]	Width:512, lr:0.001, w_d:0.1 => Score:-2.456551
[69/128]	Width:512, lr:0.001, w_d:1.0 => Score:-2.467614
[70/128]	Width:512, lr:0.001, w_d:10.0 => Score:-2.468159
[71/128]	Width:512, lr:0.001, w_d:100.0 => Score:-2.467869
[72/128]	Width:512, lr:0.001, w_d:0.0 => Score:-2.445256
[73/128]	Width:512, lr:0.01, w_d:0.0001 => Score:-2.170797
[74/128]	Width:512, lr:0.01, w_d:0.001 => Score:-2.184669
[75/128]	Width:512, lr:0.01, w_d:0.01 => Score:-2.295326
[76/128]	Width:512, lr:0.01, w_d:0.1 => Score:-2.466694
[77/128]	Width:512, lr:0.01, w_d:1.0 => Score:-2.467158
[78/128]	Width:512, lr:0.01, w_d:10.0 => Score:-2.467669
[79/128]	Width:512, lr:0.01, w_d:100.0 => Score:-2.467858
[80/128]	Width:512, lr:0.01, w_d:0.0 => Score:-2.169192
[81/128]	Width:512, lr:0.1, w_d:0.0001 => Score:-0.006924
[82/128]	Width:512, lr:0.1, w_d:0.001 => Score:-0.006781
[83/128]	Width:512, lr:0.1, w_d:0.01 => Score:-0.006425
[84/128]	Width:512, lr:0.1, w_d:0.1 => Score:-2.464699
[85/128]	Width:512, lr:0.1, w_d:1.0 => Score:-2.466332
[86/128]	Width:512, lr:0.1, w_d:10.0 => Score:-2.467512
[87/128]	Width:512, lr:0.1, w_d:100.0 => Score:-2.471090
[88/128]	Width:512, lr:0.1, w_d:0.0 => Score:-0.007114
[89/128]	Width:512, lr:1.0, w_d:0.0001 => Score:-0.008258
[90/128]	Width:512, lr:1.0, w_d:0.001 => Score:-0.013730
[91/128]	Width:512, lr:1.0, w_d:0.01 => Score:-0.013539
[92/128]	Width:512, lr:1.0, w_d:0.1 => Score:-2.464142
[93/128]	Width:512, lr:1.0, w_d:1.0 => Score:-2.465246
[94/128]	Width:512, lr:1.0, w_d:10.0 => Score:-2.724647
[95/128]	Width:512, lr:1.0, w_d:100.0 => Score:-2.838333
[96/128]	Width:512, lr:1.0, w_d:0.0 => Score:-0.002462
[97/128]	Width:1024, lr:0.001, w_d:0.0001 => Score:-2.448647
[98/128]	Width:1024, lr:0.001, w_d:0.001 => Score:-2.448801
[99/128]	Width:1024, lr:0.001, w_d:0.01 => Score:-2.450288
[100/128]	Width:1024, lr:0.001, w_d:0.1 => Score:-2.461204
[101/128]	Width:1024, lr:0.001, w_d:1.0 => Score:-2.472596
[102/128]	Width:1024, lr:0.001, w_d:10.0 => Score:-2.473610
[103/128]	Width:1024, lr:0.001, w_d:100.0 => Score:-2.474093
[104/128]	Width:1024, lr:0.001, w_d:0.0 => Score:-2.448630
[105/128]	Width:1024, lr:0.01, w_d:0.0001 => Score:-1.978097
[106/128]	Width:1024, lr:0.01, w_d:0.001 => Score:-2.001752
[107/128]	Width:1024, lr:0.01, w_d:0.01 => Score:-2.191183
[108/128]	Width:1024, lr:0.01, w_d:0.1 => Score:-2.472635
[109/128]	Width:1024, lr:0.01, w_d:1.0 => Score:-2.473252
[110/128]	Width:1024, lr:0.01, w_d:10.0 => Score:-2.473965
[111/128]	Width:1024, lr:0.01, w_d:100.0 => Score:-2.474106
[112/128]	Width:1024, lr:0.01, w_d:0.0 => Score:-1.975390
[113/128]	Width:1024, lr:0.1, w_d:0.0001 => Score:-0.013616
[114/128]	Width:1024, lr:0.1, w_d:0.001 => Score:-0.012926
[115/128]	Width:1024, lr:0.1, w_d:0.01 => Score:-0.011139
[116/128]	Width:1024, lr:0.1, w_d:0.1 => Score:-2.472269
[117/128]	Width:1024, lr:0.1, w_d:1.0 => Score:-2.473157
[118/128]	Width:1024, lr:0.1, w_d:10.0 => Score:-2.474034
[119/128]	Width:1024, lr:0.1, w_d:100.0 => Score:-2.480480
[120/128]	Width:1024, lr:0.1, w_d:0.0 => Score:-0.013496
[121/128]	Width:1024, lr:1.0, w_d:0.0001 => Score:-0.026934
[122/128]	Width:1024, lr:1.0, w_d:0.001 => Score:-0.017860
[123/128]	Width:1024, lr:1.0, w_d:0.01 => Score:-0.010274
[124/128]	Width:1024, lr:1.0, w_d:0.1 => Score:-2.472273
[125/128]	Width:1024, lr:1.0, w_d:1.0 => Score:-2.473900
[126/128]	Width:1024, lr:1.0, w_d:10.0 => Score:-3.178985
[127/128]	Width:1024, lr:1.0, w_d:100.0 => Score:-3.508032
[128/128]	Width:1024, lr:1.0, w_d:0.0 => Score:-0.007694

Best validation score after 20 epochs: -0.002462. Best configuration:
Width:512, lr:1.0, w_d:0.0
preds_train_nn.shape == torch.Size([8000, 1]), preds_val_nn.shape == torch.Size([1000, 1]), preds_test_nn.shape == torch.Size([1000, 1])
score_train == -0.0008497058879584074, score_val == -0.0005874392227269709, score_test == -0.0007418259629048407
Best params for NTK: {'C': 10.0}
Best score for NTK: -0.0011157695050773631
Best params for RBF: {'C': 100.0, 'gamma': 10.0}
Best score for RBF: -0.002507952748250246
Best kernel: ntk
preds_train_km.shape == (8000,), preds_val_km.shape == (1000,), preds_test_km.shape == (1000,)
score_train == 3.469644970395195e-05, score_val == 9.647129143266654e-05, score_test == 7.072450712803307e-05
