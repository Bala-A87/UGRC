X.shape == torch.Size([10000, 100])
scale_factor == 0.004732361529022455
Y.shape == torch.Size([10000, 1])
X_train.shape == torch.Size([8000, 100]), Y_train.shape == torch.Size([8000, 1])
X_val.shape == torch.Size([1000, 100]), Y_val.shape == torch.Size([1000, 1])
X_test.shape == torch.Size([1000, 100]), Y_test.shape == torch.Size([1000, 1])
Cross-validating across 128 models.
[1/128]	Width:128, lr:0.001, w_d:0.0001 => Score:-0.012749
[2/128]	Width:128, lr:0.001, w_d:0.001 => Score:-0.012749
[3/128]	Width:128, lr:0.001, w_d:0.01 => Score:-0.012749
[4/128]	Width:128, lr:0.001, w_d:0.1 => Score:-0.012747
[5/128]	Width:128, lr:0.001, w_d:1.0 => Score:-0.012940
[6/128]	Width:128, lr:0.001, w_d:10.0 => Score:-0.013237
[7/128]	Width:128, lr:0.001, w_d:100.0 => Score:-0.013421
[8/128]	Width:128, lr:0.001, w_d:0.0 => Score:-0.012749
[9/128]	Width:128, lr:0.01, w_d:0.0001 => Score:-0.012740
[10/128]	Width:128, lr:0.01, w_d:0.001 => Score:-0.012740
[11/128]	Width:128, lr:0.01, w_d:0.01 => Score:-0.012742
[12/128]	Width:128, lr:0.01, w_d:0.1 => Score:-0.012749
[13/128]	Width:128, lr:0.01, w_d:1.0 => Score:-0.012748
[14/128]	Width:128, lr:0.01, w_d:10.0 => Score:-0.012748
[15/128]	Width:128, lr:0.01, w_d:100.0 => Score:-0.012748
[16/128]	Width:128, lr:0.01, w_d:0.0 => Score:-0.012740
[17/128]	Width:128, lr:0.1, w_d:0.0001 => Score:-0.012728
[18/128]	Width:128, lr:0.1, w_d:0.001 => Score:-0.012732
[19/128]	Width:128, lr:0.1, w_d:0.01 => Score:-0.012752
[20/128]	Width:128, lr:0.1, w_d:0.1 => Score:-0.012750
[21/128]	Width:128, lr:0.1, w_d:1.0 => Score:-0.012750
[22/128]	Width:128, lr:0.1, w_d:10.0 => Score:-0.012751
[23/128]	Width:128, lr:0.1, w_d:100.0 => Score:-0.012748
[24/128]	Width:128, lr:0.1, w_d:0.0 => Score:-0.012728
[25/128]	Width:128, lr:1.0, w_d:0.0001 => Score:-0.012748
[26/128]	Width:128, lr:1.0, w_d:0.001 => Score:-0.012747
[27/128]	Width:128, lr:1.0, w_d:0.01 => Score:-0.012747
[28/128]	Width:128, lr:1.0, w_d:0.1 => Score:-0.012747
[29/128]	Width:128, lr:1.0, w_d:1.0 => Score:-0.012748
[30/128]	Width:128, lr:1.0, w_d:10.0 => Score:-0.013172
[31/128]	Width:128, lr:1.0, w_d:100.0 => Score:-0.012725
[32/128]	Width:128, lr:1.0, w_d:0.0 => Score:-0.012746
[33/128]	Width:256, lr:0.001, w_d:0.0001 => Score:-0.012723
[34/128]	Width:256, lr:0.001, w_d:0.001 => Score:-0.012723
[35/128]	Width:256, lr:0.001, w_d:0.01 => Score:-0.012724
[36/128]	Width:256, lr:0.001, w_d:0.1 => Score:-0.012737
[37/128]	Width:256, lr:0.001, w_d:1.0 => Score:-0.012799
[38/128]	Width:256, lr:0.001, w_d:10.0 => Score:-0.012767
[39/128]	Width:256, lr:0.001, w_d:100.0 => Score:-0.012757
[40/128]	Width:256, lr:0.001, w_d:0.0 => Score:-0.012723
[41/128]	Width:256, lr:0.01, w_d:0.0001 => Score:-0.012732
[42/128]	Width:256, lr:0.01, w_d:0.001 => Score:-0.012733
[43/128]	Width:256, lr:0.01, w_d:0.01 => Score:-0.012742
[44/128]	Width:256, lr:0.01, w_d:0.1 => Score:-0.012759
[45/128]	Width:256, lr:0.01, w_d:1.0 => Score:-0.012757
[46/128]	Width:256, lr:0.01, w_d:10.0 => Score:-0.012757
[47/128]	Width:256, lr:0.01, w_d:100.0 => Score:-0.012758
[48/128]	Width:256, lr:0.01, w_d:0.0 => Score:-0.012732
[49/128]	Width:256, lr:0.1, w_d:0.0001 => Score:-0.012746
[50/128]	Width:256, lr:0.1, w_d:0.001 => Score:-0.012749
[51/128]	Width:256, lr:0.1, w_d:0.01 => Score:-0.012758
[52/128]	Width:256, lr:0.1, w_d:0.1 => Score:-0.012758
[53/128]	Width:256, lr:0.1, w_d:1.0 => Score:-0.012758
[54/128]	Width:256, lr:0.1, w_d:10.0 => Score:-0.012757
[55/128]	Width:256, lr:0.1, w_d:100.0 => Score:-0.012756
[56/128]	Width:256, lr:0.1, w_d:0.0 => Score:-0.012745
[57/128]	Width:256, lr:1.0, w_d:0.0001 => Score:-0.012755
[58/128]	Width:256, lr:1.0, w_d:0.001 => Score:-0.012758
[59/128]	Width:256, lr:1.0, w_d:0.01 => Score:-0.012758
[60/128]	Width:256, lr:1.0, w_d:0.1 => Score:-0.012758
[61/128]	Width:256, lr:1.0, w_d:1.0 => Score:-0.012758
[62/128]	Width:256, lr:1.0, w_d:10.0 => Score:-0.023250
[63/128]	Width:256, lr:1.0, w_d:100.0 => Score:-0.027686
[64/128]	Width:256, lr:1.0, w_d:0.0 => Score:-0.012748
[65/128]	Width:512, lr:0.001, w_d:0.0001 => Score:-0.012716
[66/128]	Width:512, lr:0.001, w_d:0.001 => Score:-0.012717
[67/128]	Width:512, lr:0.001, w_d:0.01 => Score:-0.012718
[68/128]	Width:512, lr:0.001, w_d:0.1 => Score:-0.012731
[69/128]	Width:512, lr:0.001, w_d:1.0 => Score:-0.012750
[70/128]	Width:512, lr:0.001, w_d:10.0 => Score:-0.012748
[71/128]	Width:512, lr:0.001, w_d:100.0 => Score:-0.012749
[72/128]	Width:512, lr:0.001, w_d:0.0 => Score:-0.012716
[73/128]	Width:512, lr:0.01, w_d:0.0001 => Score:-0.012729
[74/128]	Width:512, lr:0.01, w_d:0.001 => Score:-0.012730
[75/128]	Width:512, lr:0.01, w_d:0.01 => Score:-0.012737
[76/128]	Width:512, lr:0.01, w_d:0.1 => Score:-0.012749
[77/128]	Width:512, lr:0.01, w_d:1.0 => Score:-0.012748
[78/128]	Width:512, lr:0.01, w_d:10.0 => Score:-0.012749
[79/128]	Width:512, lr:0.01, w_d:100.0 => Score:-0.012749
[80/128]	Width:512, lr:0.01, w_d:0.0 => Score:-0.012729
[81/128]	Width:512, lr:0.1, w_d:0.0001 => Score:-0.012736
[82/128]	Width:512, lr:0.1, w_d:0.001 => Score:-0.012739
[83/128]	Width:512, lr:0.1, w_d:0.01 => Score:-0.012749
[84/128]	Width:512, lr:0.1, w_d:0.1 => Score:-0.012749
[85/128]	Width:512, lr:0.1, w_d:1.0 => Score:-0.012749
[86/128]	Width:512, lr:0.1, w_d:10.0 => Score:-0.012749
[87/128]	Width:512, lr:0.1, w_d:100.0 => Score:-0.012749
[88/128]	Width:512, lr:0.1, w_d:0.0 => Score:-0.012734
[89/128]	Width:512, lr:1.0, w_d:0.0001 => Score:-0.012745
[90/128]	Width:512, lr:1.0, w_d:0.001 => Score:-0.012748
[91/128]	Width:512, lr:1.0, w_d:0.01 => Score:-0.012748
[92/128]	Width:512, lr:1.0, w_d:0.1 => Score:-0.012748
[93/128]	Width:512, lr:1.0, w_d:1.0 => Score:-0.012748
[94/128]	Width:512, lr:1.0, w_d:10.0 => Score:-0.030301
[95/128]	Width:512, lr:1.0, w_d:100.0 => Score:-0.022169
[96/128]	Width:512, lr:1.0, w_d:0.0 => Score:-0.012734
[97/128]	Width:1024, lr:0.001, w_d:0.0001 => Score:-0.020295
[98/128]	Width:1024, lr:0.001, w_d:0.001 => Score:-0.020294
[99/128]	Width:1024, lr:0.001, w_d:0.01 => Score:-0.020294
[100/128]	Width:1024, lr:0.001, w_d:0.1 => Score:-0.020286
[101/128]	Width:1024, lr:0.001, w_d:1.0 => Score:-0.020290
[102/128]	Width:1024, lr:0.001, w_d:10.0 => Score:-0.020287
[103/128]	Width:1024, lr:0.001, w_d:100.0 => Score:-0.020272
[104/128]	Width:1024, lr:0.001, w_d:0.0 => Score:-0.020295
[105/128]	Width:1024, lr:0.01, w_d:0.0001 => Score:-0.020263
[106/128]	Width:1024, lr:0.01, w_d:0.001 => Score:-0.020262
[107/128]	Width:1024, lr:0.01, w_d:0.01 => Score:-0.020268
[108/128]	Width:1024, lr:0.01, w_d:0.1 => Score:-0.020278
[109/128]	Width:1024, lr:0.01, w_d:1.0 => Score:-0.020274
[110/128]	Width:1024, lr:0.01, w_d:10.0 => Score:-0.020274
[111/128]	Width:1024, lr:0.01, w_d:100.0 => Score:-0.020271
[112/128]	Width:1024, lr:0.01, w_d:0.0 => Score:-0.020263
[113/128]	Width:1024, lr:0.1, w_d:0.0001 => Score:-0.020413
[114/128]	Width:1024, lr:0.1, w_d:0.001 => Score:-0.020353
[115/128]	Width:1024, lr:0.1, w_d:0.01 => Score:-0.020272
[116/128]	Width:1024, lr:0.1, w_d:0.1 => Score:-0.020272
[117/128]	Width:1024, lr:0.1, w_d:1.0 => Score:-0.020272
[118/128]	Width:1024, lr:0.1, w_d:10.0 => Score:-0.020272
[119/128]	Width:1024, lr:0.1, w_d:100.0 => Score:-0.020278
[120/128]	Width:1024, lr:0.1, w_d:0.0 => Score:-0.020446
[121/128]	Width:1024, lr:1.0, w_d:0.0001 => Score:-0.020346
[122/128]	Width:1024, lr:1.0, w_d:0.001 => Score:-0.020343
[123/128]	Width:1024, lr:1.0, w_d:0.01 => Score:-0.020342
[124/128]	Width:1024, lr:1.0, w_d:0.1 => Score:-0.020342
[125/128]	Width:1024, lr:1.0, w_d:1.0 => Score:-0.020350
[126/128]	Width:1024, lr:1.0, w_d:10.0 => Score:-0.043984
[127/128]	Width:1024, lr:1.0, w_d:100.0 => Score:-0.022595
[128/128]	Width:1024, lr:1.0, w_d:0.0 => Score:-0.020348

Best validation score after 20 epochs: -0.012716. Best configuration:
Width:512, lr:0.001, w_d:0.0
preds_train_nn.shape == torch.Size([8000, 1]), preds_val_nn.shape == torch.Size([1000, 1]), preds_test_nn.shape == torch.Size([1000, 1])
score_train == -6.146265029907227, score_val == -0.013024170882999897, score_test == -0.009998456574976444
Best params for NTK: {'C': 100.0}
Best score for NTK: -6.119905811991736
Best params for RBF: {'C': 100.0, 'gamma': 'scale'}
Best score for RBF: -5.272477015100671
Best kernel: rbf
preds_train_km.shape == (8000,), preds_val_km.shape == (1000,), preds_test_km.shape == (1000,)
score_train == 1.4776447482282888, score_val == 0.05648317235120402, score_test == 0.053065931987871906
