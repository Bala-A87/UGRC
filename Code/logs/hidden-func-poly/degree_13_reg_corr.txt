X.shape == torch.Size([10000, 100])
scale_factor == 0.004732361529022455
Y.shape == torch.Size([10000, 1])
X_train.shape == torch.Size([8000, 100]), Y_train.shape == torch.Size([8000, 1])
X_val.shape == torch.Size([1000, 100]), Y_val.shape == torch.Size([1000, 1])
X_test.shape == torch.Size([1000, 100]), Y_test.shape == torch.Size([1000, 1])
Cross-validating across 128 models.
[1/128]	Width:128, lr:0.001, w_d:0.0001 => Score:-0.029288
[2/128]	Width:128, lr:0.001, w_d:0.001 => Score:-0.029290
[3/128]	Width:128, lr:0.001, w_d:0.01 => Score:-0.029314
[4/128]	Width:128, lr:0.001, w_d:0.1 => Score:-0.029616
[5/128]	Width:128, lr:0.001, w_d:1.0 => Score:-0.032798
[6/128]	Width:128, lr:0.001, w_d:10.0 => Score:-0.031682
[7/128]	Width:128, lr:0.001, w_d:100.0 => Score:-0.030093
[8/128]	Width:128, lr:0.001, w_d:0.0 => Score:-0.029288
[9/128]	Width:128, lr:0.01, w_d:0.0001 => Score:-0.028860
[10/128]	Width:128, lr:0.01, w_d:0.001 => Score:-0.028863
[11/128]	Width:128, lr:0.01, w_d:0.01 => Score:-0.028880
[12/128]	Width:128, lr:0.01, w_d:0.1 => Score:-0.029250
[13/128]	Width:128, lr:0.01, w_d:1.0 => Score:-0.028886
[14/128]	Width:128, lr:0.01, w_d:10.0 => Score:-0.028799
[15/128]	Width:128, lr:0.01, w_d:100.0 => Score:-0.028781
[16/128]	Width:128, lr:0.01, w_d:0.0 => Score:-0.028860
[17/128]	Width:128, lr:0.1, w_d:0.0001 => Score:-0.028775
[18/128]	Width:128, lr:0.1, w_d:0.001 => Score:-0.028770
[19/128]	Width:128, lr:0.1, w_d:0.01 => Score:-0.028864
[20/128]	Width:128, lr:0.1, w_d:0.1 => Score:-0.028861
[21/128]	Width:128, lr:0.1, w_d:1.0 => Score:-0.028847
[22/128]	Width:128, lr:0.1, w_d:10.0 => Score:-0.028786
[23/128]	Width:128, lr:0.1, w_d:100.0 => Score:-0.028769
[24/128]	Width:128, lr:0.1, w_d:0.0 => Score:-0.028776
[25/128]	Width:128, lr:1.0, w_d:0.0001 => Score:-0.028758
[26/128]	Width:128, lr:1.0, w_d:0.001 => Score:-0.028725
[27/128]	Width:128, lr:1.0, w_d:0.01 => Score:-0.028723
[28/128]	Width:128, lr:1.0, w_d:0.1 => Score:-0.028724
[29/128]	Width:128, lr:1.0, w_d:1.0 => Score:-0.028723
[30/128]	Width:128, lr:1.0, w_d:10.0 => Score:-0.028735
[31/128]	Width:128, lr:1.0, w_d:100.0 => Score:-0.028761
[32/128]	Width:128, lr:1.0, w_d:0.0 => Score:-0.029643
[33/128]	Width:256, lr:0.001, w_d:0.0001 => Score:-0.029132
[34/128]	Width:256, lr:0.001, w_d:0.001 => Score:-0.029132
[35/128]	Width:256, lr:0.001, w_d:0.01 => Score:-0.029132
[36/128]	Width:256, lr:0.001, w_d:0.1 => Score:-0.029188
[37/128]	Width:256, lr:0.001, w_d:1.0 => Score:-0.029869
[38/128]	Width:256, lr:0.001, w_d:10.0 => Score:-0.029521
[39/128]	Width:256, lr:0.001, w_d:100.0 => Score:-0.029008
[40/128]	Width:256, lr:0.001, w_d:0.0 => Score:-0.029132
[41/128]	Width:256, lr:0.01, w_d:0.0001 => Score:-0.029138
[42/128]	Width:256, lr:0.01, w_d:0.001 => Score:-0.029134
[43/128]	Width:256, lr:0.01, w_d:0.01 => Score:-0.029107
[44/128]	Width:256, lr:0.01, w_d:0.1 => Score:-0.029231
[45/128]	Width:256, lr:0.01, w_d:1.0 => Score:-0.029047
[46/128]	Width:256, lr:0.01, w_d:10.0 => Score:-0.028990
[47/128]	Width:256, lr:0.01, w_d:100.0 => Score:-0.028972
[48/128]	Width:256, lr:0.01, w_d:0.0 => Score:-0.029137
[49/128]	Width:256, lr:0.1, w_d:0.0001 => Score:-0.029258
[50/128]	Width:256, lr:0.1, w_d:0.001 => Score:-0.029242
[51/128]	Width:256, lr:0.1, w_d:0.01 => Score:-0.029090
[52/128]	Width:256, lr:0.1, w_d:0.1 => Score:-0.029072
[53/128]	Width:256, lr:0.1, w_d:1.0 => Score:-0.029054
[54/128]	Width:256, lr:0.1, w_d:10.0 => Score:-0.029003
[55/128]	Width:256, lr:0.1, w_d:100.0 => Score:-0.028979
[56/128]	Width:256, lr:0.1, w_d:0.0 => Score:-0.029283
[57/128]	Width:256, lr:1.0, w_d:0.0001 => Score:-0.029834
[58/128]	Width:256, lr:1.0, w_d:0.001 => Score:-0.029210
[59/128]	Width:256, lr:1.0, w_d:0.01 => Score:-0.029204
[60/128]	Width:256, lr:1.0, w_d:0.1 => Score:-0.029191
[61/128]	Width:256, lr:1.0, w_d:1.0 => Score:-0.029159
[62/128]	Width:256, lr:1.0, w_d:10.0 => Score:-0.030774
[63/128]	Width:256, lr:1.0, w_d:100.0 => Score:-0.035782
[64/128]	Width:256, lr:1.0, w_d:0.0 => Score:-0.031710
[65/128]	Width:512, lr:0.001, w_d:0.0001 => Score:-0.028871
[66/128]	Width:512, lr:0.001, w_d:0.001 => Score:-0.028870
[67/128]	Width:512, lr:0.001, w_d:0.01 => Score:-0.028867
[68/128]	Width:512, lr:0.001, w_d:0.1 => Score:-0.028841
[69/128]	Width:512, lr:0.001, w_d:1.0 => Score:-0.028760
[70/128]	Width:512, lr:0.001, w_d:10.0 => Score:-0.028766
[71/128]	Width:512, lr:0.001, w_d:100.0 => Score:-0.028781
[72/128]	Width:512, lr:0.001, w_d:0.0 => Score:-0.028871
[73/128]	Width:512, lr:0.01, w_d:0.0001 => Score:-0.028888
[74/128]	Width:512, lr:0.01, w_d:0.001 => Score:-0.028886
[75/128]	Width:512, lr:0.01, w_d:0.01 => Score:-0.028864
[76/128]	Width:512, lr:0.01, w_d:0.1 => Score:-0.028793
[77/128]	Width:512, lr:0.01, w_d:1.0 => Score:-0.028827
[78/128]	Width:512, lr:0.01, w_d:10.0 => Score:-0.028795
[79/128]	Width:512, lr:0.01, w_d:100.0 => Score:-0.028782
[80/128]	Width:512, lr:0.01, w_d:0.0 => Score:-0.028889
[81/128]	Width:512, lr:0.1, w_d:0.0001 => Score:-0.029099
[82/128]	Width:512, lr:0.1, w_d:0.001 => Score:-0.028975
[83/128]	Width:512, lr:0.1, w_d:0.01 => Score:-0.028849
[84/128]	Width:512, lr:0.1, w_d:0.1 => Score:-0.028849
[85/128]	Width:512, lr:0.1, w_d:1.0 => Score:-0.028838
[86/128]	Width:512, lr:0.1, w_d:10.0 => Score:-0.028802
[87/128]	Width:512, lr:0.1, w_d:100.0 => Score:-0.028782
[88/128]	Width:512, lr:0.1, w_d:0.0 => Score:-0.029087
[89/128]	Width:512, lr:1.0, w_d:0.0001 => Score:-0.028984
[90/128]	Width:512, lr:1.0, w_d:0.001 => Score:-0.028962
[91/128]	Width:512, lr:1.0, w_d:0.01 => Score:-0.028965
[92/128]	Width:512, lr:1.0, w_d:0.1 => Score:-0.028968
[93/128]	Width:512, lr:1.0, w_d:1.0 => Score:-0.028955
[94/128]	Width:512, lr:1.0, w_d:10.0 => Score:-0.029123
[95/128]	Width:512, lr:1.0, w_d:100.0 => Score:-0.041960
[96/128]	Width:512, lr:1.0, w_d:0.0 => Score:-0.029583
[97/128]	Width:1024, lr:0.001, w_d:0.0001 => Score:-0.035278
[98/128]	Width:1024, lr:0.001, w_d:0.001 => Score:-0.035278
[99/128]	Width:1024, lr:0.001, w_d:0.01 => Score:-0.035278
[100/128]	Width:1024, lr:0.001, w_d:0.1 => Score:-0.035280
[101/128]	Width:1024, lr:0.001, w_d:1.0 => Score:-0.035310
[102/128]	Width:1024, lr:0.001, w_d:10.0 => Score:-0.035292
[103/128]	Width:1024, lr:0.001, w_d:100.0 => Score:-0.035249
[104/128]	Width:1024, lr:0.001, w_d:0.0 => Score:-0.035278
[105/128]	Width:1024, lr:0.01, w_d:0.0001 => Score:-0.035382
[106/128]	Width:1024, lr:0.01, w_d:0.001 => Score:-0.035376
[107/128]	Width:1024, lr:0.01, w_d:0.01 => Score:-0.035341
[108/128]	Width:1024, lr:0.01, w_d:0.1 => Score:-0.035303
[109/128]	Width:1024, lr:0.01, w_d:1.0 => Score:-0.035279
[110/128]	Width:1024, lr:0.01, w_d:10.0 => Score:-0.035256
[111/128]	Width:1024, lr:0.01, w_d:100.0 => Score:-0.035250
[112/128]	Width:1024, lr:0.01, w_d:0.0 => Score:-0.035382
[113/128]	Width:1024, lr:0.1, w_d:0.0001 => Score:-0.035505
[114/128]	Width:1024, lr:0.1, w_d:0.001 => Score:-0.035542
[115/128]	Width:1024, lr:0.1, w_d:0.01 => Score:-0.035307
[116/128]	Width:1024, lr:0.1, w_d:0.1 => Score:-0.035306
[117/128]	Width:1024, lr:0.1, w_d:1.0 => Score:-0.035296
[118/128]	Width:1024, lr:0.1, w_d:10.0 => Score:-0.035271
[119/128]	Width:1024, lr:0.1, w_d:100.0 => Score:-0.035237
[120/128]	Width:1024, lr:0.1, w_d:0.0 => Score:-0.035486
[121/128]	Width:1024, lr:1.0, w_d:0.0001 => Score:-0.036045
[122/128]	Width:1024, lr:1.0, w_d:0.001 => Score:-0.035496
[123/128]	Width:1024, lr:1.0, w_d:0.01 => Score:-0.035488
[124/128]	Width:1024, lr:1.0, w_d:0.1 => Score:-0.035489
[125/128]	Width:1024, lr:1.0, w_d:1.0 => Score:-0.035442
[126/128]	Width:1024, lr:1.0, w_d:10.0 => Score:-0.036678
[127/128]	Width:1024, lr:1.0, w_d:100.0 => Score:-0.122618
[128/128]	Width:1024, lr:1.0, w_d:0.0 => Score:-0.037144

Best validation score after 20 epochs: -0.028723. Best configuration:
Width:128, lr:1.0, w_d:1.0
preds_train_nn.shape == torch.Size([8000, 1]), preds_val_nn.shape == torch.Size([1000, 1]), preds_test_nn.shape == torch.Size([1000, 1])
score_train == -0.29152819514274597, score_val == -0.02942923828959465, score_test == -0.03878708928823471
Best params for NTK: {'C': 0.001}
Best score for NTK: -0.29154920382452754
Best params for RBF: {'C': 100.0, 'gamma': 'scale'}
Best score for RBF: -0.2223301214920182
Best kernel: rbf
preds_train_km.shape == (8000,), preds_val_km.shape == (1000,), preds_test_km.shape == (1000,)
score_train == 0.006552266584561913, score_val == 0.03739347891121343, score_test == 0.08395124890611738
