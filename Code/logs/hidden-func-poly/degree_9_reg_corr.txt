X.shape == torch.Size([10000, 100])
scale_factor == 0.004732361529022455
Y.shape == torch.Size([10000, 1])
X_train.shape == torch.Size([8000, 100]), Y_train.shape == torch.Size([8000, 1])
X_val.shape == torch.Size([1000, 100]), Y_val.shape == torch.Size([1000, 1])
X_test.shape == torch.Size([1000, 100]), Y_test.shape == torch.Size([1000, 1])
Cross-validating across 128 models.
[1/128]	Width:128, lr:0.001, w_d:0.0001 => Score:-0.121223
[2/128]	Width:128, lr:0.001, w_d:0.001 => Score:-0.121228
[3/128]	Width:128, lr:0.001, w_d:0.01 => Score:-0.121287
[4/128]	Width:128, lr:0.001, w_d:0.1 => Score:-0.122074
[5/128]	Width:128, lr:0.001, w_d:1.0 => Score:-0.125145
[6/128]	Width:128, lr:0.001, w_d:10.0 => Score:-0.122230
[7/128]	Width:128, lr:0.001, w_d:100.0 => Score:-0.119738
[8/128]	Width:128, lr:0.001, w_d:0.0 => Score:-0.121222
[9/128]	Width:128, lr:0.01, w_d:0.0001 => Score:-0.117990
[10/128]	Width:128, lr:0.01, w_d:0.001 => Score:-0.117993
[11/128]	Width:128, lr:0.01, w_d:0.01 => Score:-0.118021
[12/128]	Width:128, lr:0.01, w_d:0.1 => Score:-0.119345
[13/128]	Width:128, lr:0.01, w_d:1.0 => Score:-0.118613
[14/128]	Width:128, lr:0.01, w_d:10.0 => Score:-0.118117
[15/128]	Width:128, lr:0.01, w_d:100.0 => Score:-0.118142
[16/128]	Width:128, lr:0.01, w_d:0.0 => Score:-0.117990
[17/128]	Width:128, lr:0.1, w_d:0.0001 => Score:-0.117625
[18/128]	Width:128, lr:0.1, w_d:0.001 => Score:-0.117663
[19/128]	Width:128, lr:0.1, w_d:0.01 => Score:-0.118034
[20/128]	Width:128, lr:0.1, w_d:0.1 => Score:-0.117995
[21/128]	Width:128, lr:0.1, w_d:1.0 => Score:-0.118037
[22/128]	Width:128, lr:0.1, w_d:10.0 => Score:-0.118120
[23/128]	Width:128, lr:0.1, w_d:100.0 => Score:-0.118159
[24/128]	Width:128, lr:0.1, w_d:0.0 => Score:-0.117610
[25/128]	Width:128, lr:1.0, w_d:0.0001 => Score:-0.083970
[26/128]	Width:128, lr:1.0, w_d:0.001 => Score:-0.118333
[27/128]	Width:128, lr:1.0, w_d:0.01 => Score:-0.118002
[28/128]	Width:128, lr:1.0, w_d:0.1 => Score:-0.118009
[29/128]	Width:128, lr:1.0, w_d:1.0 => Score:-0.118093
[30/128]	Width:128, lr:1.0, w_d:10.0 => Score:-0.118596
[31/128]	Width:128, lr:1.0, w_d:100.0 => Score:-0.120205
[32/128]	Width:128, lr:1.0, w_d:0.0 => Score:-0.080256
[33/128]	Width:256, lr:0.001, w_d:0.0001 => Score:-0.119448
[34/128]	Width:256, lr:0.001, w_d:0.001 => Score:-0.119448
[35/128]	Width:256, lr:0.001, w_d:0.01 => Score:-0.119465
[36/128]	Width:256, lr:0.001, w_d:0.1 => Score:-0.119726
[37/128]	Width:256, lr:0.001, w_d:1.0 => Score:-0.120538
[38/128]	Width:256, lr:0.001, w_d:10.0 => Score:-0.119849
[39/128]	Width:256, lr:0.001, w_d:100.0 => Score:-0.119204
[40/128]	Width:256, lr:0.001, w_d:0.0 => Score:-0.119448
[41/128]	Width:256, lr:0.01, w_d:0.0001 => Score:-0.119089
[42/128]	Width:256, lr:0.01, w_d:0.001 => Score:-0.119090
[43/128]	Width:256, lr:0.01, w_d:0.01 => Score:-0.119100
[44/128]	Width:256, lr:0.01, w_d:0.1 => Score:-0.119364
[45/128]	Width:256, lr:0.01, w_d:1.0 => Score:-0.119181
[46/128]	Width:256, lr:0.01, w_d:10.0 => Score:-0.119151
[47/128]	Width:256, lr:0.01, w_d:100.0 => Score:-0.119168
[48/128]	Width:256, lr:0.01, w_d:0.0 => Score:-0.119089
[49/128]	Width:256, lr:0.1, w_d:0.0001 => Score:-0.118927
[50/128]	Width:256, lr:0.1, w_d:0.001 => Score:-0.118967
[51/128]	Width:256, lr:0.1, w_d:0.01 => Score:-0.119112
[52/128]	Width:256, lr:0.1, w_d:0.1 => Score:-0.119110
[53/128]	Width:256, lr:0.1, w_d:1.0 => Score:-0.119114
[54/128]	Width:256, lr:0.1, w_d:10.0 => Score:-0.119163
[55/128]	Width:256, lr:0.1, w_d:100.0 => Score:-0.119174
[56/128]	Width:256, lr:0.1, w_d:0.0 => Score:-0.118910
[57/128]	Width:256, lr:1.0, w_d:0.0001 => Score:-0.121105
[58/128]	Width:256, lr:1.0, w_d:0.001 => Score:-0.109141
[59/128]	Width:256, lr:1.0, w_d:0.01 => Score:-0.119147
[60/128]	Width:256, lr:1.0, w_d:0.1 => Score:-0.119143
[61/128]	Width:256, lr:1.0, w_d:1.0 => Score:-0.119156
[62/128]	Width:256, lr:1.0, w_d:10.0 => Score:-0.123964
[63/128]	Width:256, lr:1.0, w_d:100.0 => Score:-0.137856
[64/128]	Width:256, lr:1.0, w_d:0.0 => Score:-0.097005
[65/128]	Width:512, lr:0.001, w_d:0.0001 => Score:-0.117803
[66/128]	Width:512, lr:0.001, w_d:0.001 => Score:-0.117803
[67/128]	Width:512, lr:0.001, w_d:0.01 => Score:-0.117802
[68/128]	Width:512, lr:0.001, w_d:0.1 => Score:-0.117801
[69/128]	Width:512, lr:0.001, w_d:1.0 => Score:-0.117819
[70/128]	Width:512, lr:0.001, w_d:10.0 => Score:-0.117870
[71/128]	Width:512, lr:0.001, w_d:100.0 => Score:-0.117947
[72/128]	Width:512, lr:0.001, w_d:0.0 => Score:-0.117803
[73/128]	Width:512, lr:0.01, w_d:0.0001 => Score:-0.117762
[74/128]	Width:512, lr:0.01, w_d:0.001 => Score:-0.117766
[75/128]	Width:512, lr:0.01, w_d:0.01 => Score:-0.117783
[76/128]	Width:512, lr:0.01, w_d:0.1 => Score:-0.117814
[77/128]	Width:512, lr:0.01, w_d:1.0 => Score:-0.117837
[78/128]	Width:512, lr:0.01, w_d:10.0 => Score:-0.117920
[79/128]	Width:512, lr:0.01, w_d:100.0 => Score:-0.117949
[80/128]	Width:512, lr:0.01, w_d:0.0 => Score:-0.117762
[81/128]	Width:512, lr:0.1, w_d:0.0001 => Score:-0.117526
[82/128]	Width:512, lr:0.1, w_d:0.001 => Score:-0.117503
[83/128]	Width:512, lr:0.1, w_d:0.01 => Score:-0.117801
[84/128]	Width:512, lr:0.1, w_d:0.1 => Score:-0.117804
[85/128]	Width:512, lr:0.1, w_d:1.0 => Score:-0.117843
[86/128]	Width:512, lr:0.1, w_d:10.0 => Score:-0.117936
[87/128]	Width:512, lr:0.1, w_d:100.0 => Score:-0.117985
[88/128]	Width:512, lr:0.1, w_d:0.0 => Score:-0.117508
[89/128]	Width:512, lr:1.0, w_d:0.0001 => Score:-0.123854
[90/128]	Width:512, lr:1.0, w_d:0.001 => Score:-0.108293
[91/128]	Width:512, lr:1.0, w_d:0.01 => Score:-0.117833
[92/128]	Width:512, lr:1.0, w_d:0.1 => Score:-0.117859
[93/128]	Width:512, lr:1.0, w_d:1.0 => Score:-0.118032
[94/128]	Width:512, lr:1.0, w_d:10.0 => Score:-0.118267
[95/128]	Width:512, lr:1.0, w_d:100.0 => Score:-0.119718
[96/128]	Width:512, lr:1.0, w_d:0.0 => Score:-0.111077
[97/128]	Width:1024, lr:0.001, w_d:0.0001 => Score:-0.122032
[98/128]	Width:1024, lr:0.001, w_d:0.001 => Score:-0.122032
[99/128]	Width:1024, lr:0.001, w_d:0.01 => Score:-0.122036
[100/128]	Width:1024, lr:0.001, w_d:0.1 => Score:-0.122061
[101/128]	Width:1024, lr:0.001, w_d:1.0 => Score:-0.122183
[102/128]	Width:1024, lr:0.001, w_d:10.0 => Score:-0.122198
[103/128]	Width:1024, lr:0.001, w_d:100.0 => Score:-0.122141
[104/128]	Width:1024, lr:0.001, w_d:0.0 => Score:-0.122032
[105/128]	Width:1024, lr:0.01, w_d:0.0001 => Score:-0.121914
[106/128]	Width:1024, lr:0.01, w_d:0.001 => Score:-0.121924
[107/128]	Width:1024, lr:0.01, w_d:0.01 => Score:-0.122003
[108/128]	Width:1024, lr:0.01, w_d:0.1 => Score:-0.122148
[109/128]	Width:1024, lr:0.01, w_d:1.0 => Score:-0.122108
[110/128]	Width:1024, lr:0.01, w_d:10.0 => Score:-0.122127
[111/128]	Width:1024, lr:0.01, w_d:100.0 => Score:-0.122141
[112/128]	Width:1024, lr:0.01, w_d:0.0 => Score:-0.121913
[113/128]	Width:1024, lr:0.1, w_d:0.0001 => Score:-0.121234
[114/128]	Width:1024, lr:0.1, w_d:0.001 => Score:-0.121282
[115/128]	Width:1024, lr:0.1, w_d:0.01 => Score:-0.122096
[116/128]	Width:1024, lr:0.1, w_d:0.1 => Score:-0.122099
[117/128]	Width:1024, lr:0.1, w_d:1.0 => Score:-0.122095
[118/128]	Width:1024, lr:0.1, w_d:10.0 => Score:-0.122133
[119/128]	Width:1024, lr:0.1, w_d:100.0 => Score:-0.122178
[120/128]	Width:1024, lr:0.1, w_d:0.0 => Score:-0.121223
[121/128]	Width:1024, lr:1.0, w_d:0.0001 => Score:-0.110647
[122/128]	Width:1024, lr:1.0, w_d:0.001 => Score:-0.121918
[123/128]	Width:1024, lr:1.0, w_d:0.01 => Score:-0.122097
[124/128]	Width:1024, lr:1.0, w_d:0.1 => Score:-0.122097
[125/128]	Width:1024, lr:1.0, w_d:1.0 => Score:-0.122141
[126/128]	Width:1024, lr:1.0, w_d:10.0 => Score:-0.146100
[127/128]	Width:1024, lr:1.0, w_d:100.0 => Score:-0.214970
[128/128]	Width:1024, lr:1.0, w_d:0.0 => Score:-0.071093

Best validation score after 20 epochs: -0.071093. Best configuration:
Width:1024, lr:1.0, w_d:0.0
preds_train_nn.shape == torch.Size([8000, 1]), preds_val_nn.shape == torch.Size([1000, 1]), preds_test_nn.shape == torch.Size([1000, 1])
score_train == -0.15922586619853973, score_val == -0.00683895219117403, score_test == -0.01733282394707203
Best params for NTK: {'C': 10.0}
Best score for NTK: -0.07611998933376624
Best params for RBF: {'C': 100.0, 'gamma': 'scale'}
Best score for RBF: -0.04779747773993011
Best kernel: rbf
preds_train_km.shape == (8000,), preds_val_km.shape == (1000,), preds_test_km.shape == (1000,)
score_train == 0.0037449209003824154, score_val == 0.012781132771038883, score_test == 0.011194599294196951
