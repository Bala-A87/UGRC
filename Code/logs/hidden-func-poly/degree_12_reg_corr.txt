X.shape == torch.Size([10000, 100])
scale_factor == 0.004732361529022455
Y.shape == torch.Size([10000, 1])
X_train.shape == torch.Size([8000, 100]), Y_train.shape == torch.Size([8000, 1])
X_val.shape == torch.Size([1000, 100]), Y_val.shape == torch.Size([1000, 1])
X_test.shape == torch.Size([1000, 100]), Y_test.shape == torch.Size([1000, 1])
Cross-validating across 128 models.
[1/128]	Width:128, lr:0.001, w_d:0.0001 => Score:-0.043446
[2/128]	Width:128, lr:0.001, w_d:0.001 => Score:-0.043448
[3/128]	Width:128, lr:0.001, w_d:0.01 => Score:-0.043468
[4/128]	Width:128, lr:0.001, w_d:0.1 => Score:-0.043746
[5/128]	Width:128, lr:0.001, w_d:1.0 => Score:-0.046320
[6/128]	Width:128, lr:0.001, w_d:10.0 => Score:-0.045103
[7/128]	Width:128, lr:0.001, w_d:100.0 => Score:-0.043763
[8/128]	Width:128, lr:0.001, w_d:0.0 => Score:-0.043446
[9/128]	Width:128, lr:0.01, w_d:0.0001 => Score:-0.043177
[10/128]	Width:128, lr:0.01, w_d:0.001 => Score:-0.043177
[11/128]	Width:128, lr:0.01, w_d:0.01 => Score:-0.043166
[12/128]	Width:128, lr:0.01, w_d:0.1 => Score:-0.043299
[13/128]	Width:128, lr:0.01, w_d:1.0 => Score:-0.043153
[14/128]	Width:128, lr:0.01, w_d:10.0 => Score:-0.043169
[15/128]	Width:128, lr:0.01, w_d:100.0 => Score:-0.043172
[16/128]	Width:128, lr:0.01, w_d:0.0 => Score:-0.043178
[17/128]	Width:128, lr:0.1, w_d:0.0001 => Score:-0.043430
[18/128]	Width:128, lr:0.1, w_d:0.001 => Score:-0.043337
[19/128]	Width:128, lr:0.1, w_d:0.01 => Score:-0.043176
[20/128]	Width:128, lr:0.1, w_d:0.1 => Score:-0.043169
[21/128]	Width:128, lr:0.1, w_d:1.0 => Score:-0.043172
[22/128]	Width:128, lr:0.1, w_d:10.0 => Score:-0.043179
[23/128]	Width:128, lr:0.1, w_d:100.0 => Score:-0.043173
[24/128]	Width:128, lr:0.1, w_d:0.0 => Score:-0.043443
[25/128]	Width:128, lr:1.0, w_d:0.0001 => Score:-0.044627
[26/128]	Width:128, lr:1.0, w_d:0.001 => Score:-0.043250
[27/128]	Width:128, lr:1.0, w_d:0.01 => Score:-0.043251
[28/128]	Width:128, lr:1.0, w_d:0.1 => Score:-0.043253
[29/128]	Width:128, lr:1.0, w_d:1.0 => Score:-0.043256
[30/128]	Width:128, lr:1.0, w_d:10.0 => Score:-0.043091
[31/128]	Width:128, lr:1.0, w_d:100.0 => Score:-0.043168
[32/128]	Width:128, lr:1.0, w_d:0.0 => Score:-0.044266
[33/128]	Width:256, lr:0.001, w_d:0.0001 => Score:-0.043341
[34/128]	Width:256, lr:0.001, w_d:0.001 => Score:-0.043341
[35/128]	Width:256, lr:0.001, w_d:0.01 => Score:-0.043341
[36/128]	Width:256, lr:0.001, w_d:0.1 => Score:-0.043357
[37/128]	Width:256, lr:0.001, w_d:1.0 => Score:-0.043737
[38/128]	Width:256, lr:0.001, w_d:10.0 => Score:-0.043514
[39/128]	Width:256, lr:0.001, w_d:100.0 => Score:-0.043379
[40/128]	Width:256, lr:0.001, w_d:0.0 => Score:-0.043340
[41/128]	Width:256, lr:0.01, w_d:0.0001 => Score:-0.043384
[42/128]	Width:256, lr:0.01, w_d:0.001 => Score:-0.043385
[43/128]	Width:256, lr:0.01, w_d:0.01 => Score:-0.043383
[44/128]	Width:256, lr:0.01, w_d:0.1 => Score:-0.043371
[45/128]	Width:256, lr:0.01, w_d:1.0 => Score:-0.043382
[46/128]	Width:256, lr:0.01, w_d:10.0 => Score:-0.043395
[47/128]	Width:256, lr:0.01, w_d:100.0 => Score:-0.043396
[48/128]	Width:256, lr:0.01, w_d:0.0 => Score:-0.043384
[49/128]	Width:256, lr:0.1, w_d:0.0001 => Score:-0.043568
[50/128]	Width:256, lr:0.1, w_d:0.001 => Score:-0.043483
[51/128]	Width:256, lr:0.1, w_d:0.01 => Score:-0.043378
[52/128]	Width:256, lr:0.1, w_d:0.1 => Score:-0.043386
[53/128]	Width:256, lr:0.1, w_d:1.0 => Score:-0.043386
[54/128]	Width:256, lr:0.1, w_d:10.0 => Score:-0.043390
[55/128]	Width:256, lr:0.1, w_d:100.0 => Score:-0.043392
[56/128]	Width:256, lr:0.1, w_d:0.0 => Score:-0.043579
[57/128]	Width:256, lr:1.0, w_d:0.0001 => Score:-0.045804
[58/128]	Width:256, lr:1.0, w_d:0.001 => Score:-0.043367
[59/128]	Width:256, lr:1.0, w_d:0.01 => Score:-0.043367
[60/128]	Width:256, lr:1.0, w_d:0.1 => Score:-0.043366
[61/128]	Width:256, lr:1.0, w_d:1.0 => Score:-0.043376
[62/128]	Width:256, lr:1.0, w_d:10.0 => Score:-0.044352
[63/128]	Width:256, lr:1.0, w_d:100.0 => Score:-0.049609
[64/128]	Width:256, lr:1.0, w_d:0.0 => Score:-0.043917
[65/128]	Width:512, lr:0.001, w_d:0.0001 => Score:-0.043267
[66/128]	Width:512, lr:0.001, w_d:0.001 => Score:-0.043267
[67/128]	Width:512, lr:0.001, w_d:0.01 => Score:-0.043268
[68/128]	Width:512, lr:0.001, w_d:0.1 => Score:-0.043274
[69/128]	Width:512, lr:0.001, w_d:1.0 => Score:-0.043309
[70/128]	Width:512, lr:0.001, w_d:10.0 => Score:-0.043294
[71/128]	Width:512, lr:0.001, w_d:100.0 => Score:-0.043279
[72/128]	Width:512, lr:0.001, w_d:0.0 => Score:-0.043267
[73/128]	Width:512, lr:0.01, w_d:0.0001 => Score:-0.043287
[74/128]	Width:512, lr:0.01, w_d:0.001 => Score:-0.043288
[75/128]	Width:512, lr:0.01, w_d:0.01 => Score:-0.043286
[76/128]	Width:512, lr:0.01, w_d:0.1 => Score:-0.043289
[77/128]	Width:512, lr:0.01, w_d:1.0 => Score:-0.043277
[78/128]	Width:512, lr:0.01, w_d:10.0 => Score:-0.043278
[79/128]	Width:512, lr:0.01, w_d:100.0 => Score:-0.043280
[80/128]	Width:512, lr:0.01, w_d:0.0 => Score:-0.043287
[81/128]	Width:512, lr:0.1, w_d:0.0001 => Score:-0.043472
[82/128]	Width:512, lr:0.1, w_d:0.001 => Score:-0.043387
[83/128]	Width:512, lr:0.1, w_d:0.01 => Score:-0.043279
[84/128]	Width:512, lr:0.1, w_d:0.1 => Score:-0.043278
[85/128]	Width:512, lr:0.1, w_d:1.0 => Score:-0.043278
[86/128]	Width:512, lr:0.1, w_d:10.0 => Score:-0.043280
[87/128]	Width:512, lr:0.1, w_d:100.0 => Score:-0.043277
[88/128]	Width:512, lr:0.1, w_d:0.0 => Score:-0.043483
[89/128]	Width:512, lr:1.0, w_d:0.0001 => Score:-0.043906
[90/128]	Width:512, lr:1.0, w_d:0.001 => Score:-0.043277
[91/128]	Width:512, lr:1.0, w_d:0.01 => Score:-0.043277
[92/128]	Width:512, lr:1.0, w_d:0.1 => Score:-0.043278
[93/128]	Width:512, lr:1.0, w_d:1.0 => Score:-0.043280
[94/128]	Width:512, lr:1.0, w_d:10.0 => Score:-0.047604
[95/128]	Width:512, lr:1.0, w_d:100.0 => Score:-0.071133
[96/128]	Width:512, lr:1.0, w_d:0.0 => Score:-0.044292
[97/128]	Width:1024, lr:0.001, w_d:0.0001 => Score:-0.055507
[98/128]	Width:1024, lr:0.001, w_d:0.001 => Score:-0.055507
[99/128]	Width:1024, lr:0.001, w_d:0.01 => Score:-0.055507
[100/128]	Width:1024, lr:0.001, w_d:0.1 => Score:-0.055502
[101/128]	Width:1024, lr:0.001, w_d:1.0 => Score:-0.055451
[102/128]	Width:1024, lr:0.001, w_d:10.0 => Score:-0.055459
[103/128]	Width:1024, lr:0.001, w_d:100.0 => Score:-0.055522
[104/128]	Width:1024, lr:0.001, w_d:0.0 => Score:-0.055507
[105/128]	Width:1024, lr:0.01, w_d:0.0001 => Score:-0.055538
[106/128]	Width:1024, lr:0.01, w_d:0.001 => Score:-0.055538
[107/128]	Width:1024, lr:0.01, w_d:0.01 => Score:-0.055521
[108/128]	Width:1024, lr:0.01, w_d:0.1 => Score:-0.055466
[109/128]	Width:1024, lr:0.01, w_d:1.0 => Score:-0.055500
[110/128]	Width:1024, lr:0.01, w_d:10.0 => Score:-0.055517
[111/128]	Width:1024, lr:0.01, w_d:100.0 => Score:-0.055523
[112/128]	Width:1024, lr:0.01, w_d:0.0 => Score:-0.055539
[113/128]	Width:1024, lr:0.1, w_d:0.0001 => Score:-0.056158
[114/128]	Width:1024, lr:0.1, w_d:0.001 => Score:-0.055939
[115/128]	Width:1024, lr:0.1, w_d:0.01 => Score:-0.055510
[116/128]	Width:1024, lr:0.1, w_d:0.1 => Score:-0.055510
[117/128]	Width:1024, lr:0.1, w_d:1.0 => Score:-0.055516
[118/128]	Width:1024, lr:0.1, w_d:10.0 => Score:-0.055534
[119/128]	Width:1024, lr:0.1, w_d:100.0 => Score:-0.055562
[120/128]	Width:1024, lr:0.1, w_d:0.0 => Score:-0.056248
[121/128]	Width:1024, lr:1.0, w_d:0.0001 => Score:-0.058253
[122/128]	Width:1024, lr:1.0, w_d:0.001 => Score:-0.055781
[123/128]	Width:1024, lr:1.0, w_d:0.01 => Score:-0.055779
[124/128]	Width:1024, lr:1.0, w_d:0.1 => Score:-0.055789
[125/128]	Width:1024, lr:1.0, w_d:1.0 => Score:-0.055772
[126/128]	Width:1024, lr:1.0, w_d:10.0 => Score:-0.064132
[127/128]	Width:1024, lr:1.0, w_d:100.0 => Score:-0.086432
[128/128]	Width:1024, lr:1.0, w_d:0.0 => Score:-0.056849

Best validation score after 20 epochs: -0.043091. Best configuration:
Width:128, lr:1.0, w_d:10.0
preds_train_nn.shape == torch.Size([8000, 1]), preds_val_nn.shape == torch.Size([1000, 1]), preds_test_nn.shape == torch.Size([1000, 1])
score_train == -0.21320943534374237, score_val == -0.0438716895878315, score_test == -0.044401008635759354
Best params for NTK: {'C': 10.0}
Best score for NTK: -0.20884739670865893
Best params for RBF: {'C': 100.0, 'gamma': 'scale'}
Best score for RBF: -0.16583311055561445
Best kernel: rbf
preds_train_km.shape == (8000,), preds_val_km.shape == (1000,), preds_test_km.shape == (1000,)
score_train == 0.006511613912767662, score_val == 0.04124693323231129, score_test == 0.06331432781731804
