X.shape == torch.Size([10000, 100])
scale_factor == 0.004732361529022455
Y.shape == torch.Size([10000, 1])
X_train.shape == torch.Size([8000, 100]), Y_train.shape == torch.Size([8000, 1])
X_val.shape == torch.Size([1000, 100]), Y_val.shape == torch.Size([1000, 1])
X_test.shape == torch.Size([1000, 100]), Y_test.shape == torch.Size([1000, 1])
Cross-validating across 128 models.
[1/128]	Width:128, lr:0.001, w_d:0.0001 => Score:-0.055412
[2/128]	Width:128, lr:0.001, w_d:0.001 => Score:-0.055415
[3/128]	Width:128, lr:0.001, w_d:0.01 => Score:-0.055439
[4/128]	Width:128, lr:0.001, w_d:0.1 => Score:-0.055768
[5/128]	Width:128, lr:0.001, w_d:1.0 => Score:-0.058309
[6/128]	Width:128, lr:0.001, w_d:10.0 => Score:-0.056755
[7/128]	Width:128, lr:0.001, w_d:100.0 => Score:-0.055412
[8/128]	Width:128, lr:0.001, w_d:0.0 => Score:-0.055412
[9/128]	Width:128, lr:0.01, w_d:0.0001 => Score:-0.055060
[10/128]	Width:128, lr:0.01, w_d:0.001 => Score:-0.055056
[11/128]	Width:128, lr:0.01, w_d:0.01 => Score:-0.055031
[12/128]	Width:128, lr:0.01, w_d:0.1 => Score:-0.055041
[13/128]	Width:128, lr:0.01, w_d:1.0 => Score:-0.054956
[14/128]	Width:128, lr:0.01, w_d:10.0 => Score:-0.055020
[15/128]	Width:128, lr:0.01, w_d:100.0 => Score:-0.055016
[16/128]	Width:128, lr:0.01, w_d:0.0 => Score:-0.055059
[17/128]	Width:128, lr:0.1, w_d:0.0001 => Score:-0.055100
[18/128]	Width:128, lr:0.1, w_d:0.001 => Score:-0.055112
[19/128]	Width:128, lr:0.1, w_d:0.01 => Score:-0.055037
[20/128]	Width:128, lr:0.1, w_d:0.1 => Score:-0.055065
[21/128]	Width:128, lr:0.1, w_d:1.0 => Score:-0.055055
[22/128]	Width:128, lr:0.1, w_d:10.0 => Score:-0.055032
[23/128]	Width:128, lr:0.1, w_d:100.0 => Score:-0.055013
[24/128]	Width:128, lr:0.1, w_d:0.0 => Score:-0.055092
[25/128]	Width:128, lr:1.0, w_d:0.0001 => Score:-0.055055
[26/128]	Width:128, lr:1.0, w_d:0.001 => Score:-0.055184
[27/128]	Width:128, lr:1.0, w_d:0.01 => Score:-0.055165
[28/128]	Width:128, lr:1.0, w_d:0.1 => Score:-0.055172
[29/128]	Width:128, lr:1.0, w_d:1.0 => Score:-0.055143
[30/128]	Width:128, lr:1.0, w_d:10.0 => Score:-0.055049
[31/128]	Width:128, lr:1.0, w_d:100.0 => Score:-0.055059
[32/128]	Width:128, lr:1.0, w_d:0.0 => Score:-0.053253
[33/128]	Width:256, lr:0.001, w_d:0.0001 => Score:-0.054910
[34/128]	Width:256, lr:0.001, w_d:0.001 => Score:-0.054910
[35/128]	Width:256, lr:0.001, w_d:0.01 => Score:-0.054912
[36/128]	Width:256, lr:0.001, w_d:0.1 => Score:-0.054946
[37/128]	Width:256, lr:0.001, w_d:1.0 => Score:-0.055378
[38/128]	Width:256, lr:0.001, w_d:10.0 => Score:-0.055101
[39/128]	Width:256, lr:0.001, w_d:100.0 => Score:-0.054947
[40/128]	Width:256, lr:0.001, w_d:0.0 => Score:-0.054910
[41/128]	Width:256, lr:0.01, w_d:0.0001 => Score:-0.054971
[42/128]	Width:256, lr:0.01, w_d:0.001 => Score:-0.054974
[43/128]	Width:256, lr:0.01, w_d:0.01 => Score:-0.054980
[44/128]	Width:256, lr:0.01, w_d:0.1 => Score:-0.054956
[45/128]	Width:256, lr:0.01, w_d:1.0 => Score:-0.054953
[46/128]	Width:256, lr:0.01, w_d:10.0 => Score:-0.054970
[47/128]	Width:256, lr:0.01, w_d:100.0 => Score:-0.054966
[48/128]	Width:256, lr:0.01, w_d:0.0 => Score:-0.054970
[49/128]	Width:256, lr:0.1, w_d:0.0001 => Score:-0.054878
[50/128]	Width:256, lr:0.1, w_d:0.001 => Score:-0.054924
[51/128]	Width:256, lr:0.1, w_d:0.01 => Score:-0.054987
[52/128]	Width:256, lr:0.1, w_d:0.1 => Score:-0.055005
[53/128]	Width:256, lr:0.1, w_d:1.0 => Score:-0.054994
[54/128]	Width:256, lr:0.1, w_d:10.0 => Score:-0.054974
[55/128]	Width:256, lr:0.1, w_d:100.0 => Score:-0.054962
[56/128]	Width:256, lr:0.1, w_d:0.0 => Score:-0.054877
[57/128]	Width:256, lr:1.0, w_d:0.0001 => Score:-0.054255
[58/128]	Width:256, lr:1.0, w_d:0.001 => Score:-0.054985
[59/128]	Width:256, lr:1.0, w_d:0.01 => Score:-0.054984
[60/128]	Width:256, lr:1.0, w_d:0.1 => Score:-0.054985
[61/128]	Width:256, lr:1.0, w_d:1.0 => Score:-0.054963
[62/128]	Width:256, lr:1.0, w_d:10.0 => Score:-0.056188
[63/128]	Width:256, lr:1.0, w_d:100.0 => Score:-0.060643
[64/128]	Width:256, lr:1.0, w_d:0.0 => Score:-0.050968
[65/128]	Width:512, lr:0.001, w_d:0.0001 => Score:-0.054681
[66/128]	Width:512, lr:0.001, w_d:0.001 => Score:-0.054681
[67/128]	Width:512, lr:0.001, w_d:0.01 => Score:-0.054685
[68/128]	Width:512, lr:0.001, w_d:0.1 => Score:-0.054716
[69/128]	Width:512, lr:0.001, w_d:1.0 => Score:-0.054774
[70/128]	Width:512, lr:0.001, w_d:10.0 => Score:-0.054724
[71/128]	Width:512, lr:0.001, w_d:100.0 => Score:-0.054685
[72/128]	Width:512, lr:0.001, w_d:0.0 => Score:-0.054681
[73/128]	Width:512, lr:0.01, w_d:0.0001 => Score:-0.054685
[74/128]	Width:512, lr:0.01, w_d:0.001 => Score:-0.054691
[75/128]	Width:512, lr:0.01, w_d:0.01 => Score:-0.054699
[76/128]	Width:512, lr:0.01, w_d:0.1 => Score:-0.054734
[77/128]	Width:512, lr:0.01, w_d:1.0 => Score:-0.054702
[78/128]	Width:512, lr:0.01, w_d:10.0 => Score:-0.054688
[79/128]	Width:512, lr:0.01, w_d:100.0 => Score:-0.054686
[80/128]	Width:512, lr:0.01, w_d:0.0 => Score:-0.054684
[81/128]	Width:512, lr:0.1, w_d:0.0001 => Score:-0.054958
[82/128]	Width:512, lr:0.1, w_d:0.001 => Score:-0.055001
[83/128]	Width:512, lr:0.1, w_d:0.01 => Score:-0.054713
[84/128]	Width:512, lr:0.1, w_d:0.1 => Score:-0.054711
[85/128]	Width:512, lr:0.1, w_d:1.0 => Score:-0.054709
[86/128]	Width:512, lr:0.1, w_d:10.0 => Score:-0.054701
[87/128]	Width:512, lr:0.1, w_d:100.0 => Score:-0.054698
[88/128]	Width:512, lr:0.1, w_d:0.0 => Score:-0.055011
[89/128]	Width:512, lr:1.0, w_d:0.0001 => Score:-0.052066
[90/128]	Width:512, lr:1.0, w_d:0.001 => Score:-0.054933
[91/128]	Width:512, lr:1.0, w_d:0.01 => Score:-0.054932
[92/128]	Width:512, lr:1.0, w_d:0.1 => Score:-0.054940
[93/128]	Width:512, lr:1.0, w_d:1.0 => Score:-0.054894
[94/128]	Width:512, lr:1.0, w_d:10.0 => Score:-0.054825
[95/128]	Width:512, lr:1.0, w_d:100.0 => Score:-0.056150
[96/128]	Width:512, lr:1.0, w_d:0.0 => Score:-0.051303
[97/128]	Width:1024, lr:0.001, w_d:0.0001 => Score:-0.069605
[98/128]	Width:1024, lr:0.001, w_d:0.001 => Score:-0.069604
[99/128]	Width:1024, lr:0.001, w_d:0.01 => Score:-0.069600
[100/128]	Width:1024, lr:0.001, w_d:0.1 => Score:-0.069564
[101/128]	Width:1024, lr:0.001, w_d:1.0 => Score:-0.069437
[102/128]	Width:1024, lr:0.001, w_d:10.0 => Score:-0.069443
[103/128]	Width:1024, lr:0.001, w_d:100.0 => Score:-0.069519
[104/128]	Width:1024, lr:0.001, w_d:0.0 => Score:-0.069605
[105/128]	Width:1024, lr:0.01, w_d:0.0001 => Score:-0.069710
[106/128]	Width:1024, lr:0.01, w_d:0.001 => Score:-0.069704
[107/128]	Width:1024, lr:0.01, w_d:0.01 => Score:-0.069631
[108/128]	Width:1024, lr:0.01, w_d:0.1 => Score:-0.069462
[109/128]	Width:1024, lr:0.01, w_d:1.0 => Score:-0.069528
[110/128]	Width:1024, lr:0.01, w_d:10.0 => Score:-0.069526
[111/128]	Width:1024, lr:0.01, w_d:100.0 => Score:-0.069520
[112/128]	Width:1024, lr:0.01, w_d:0.0 => Score:-0.069703
[113/128]	Width:1024, lr:0.1, w_d:0.0001 => Score:-0.070098
[114/128]	Width:1024, lr:0.1, w_d:0.001 => Score:-0.069999
[115/128]	Width:1024, lr:0.1, w_d:0.01 => Score:-0.069547
[116/128]	Width:1024, lr:0.1, w_d:0.1 => Score:-0.069554
[117/128]	Width:1024, lr:0.1, w_d:1.0 => Score:-0.069551
[118/128]	Width:1024, lr:0.1, w_d:10.0 => Score:-0.069548
[119/128]	Width:1024, lr:0.1, w_d:100.0 => Score:-0.069485
[120/128]	Width:1024, lr:0.1, w_d:0.0 => Score:-0.070150
[121/128]	Width:1024, lr:1.0, w_d:0.0001 => Score:-0.068429
[122/128]	Width:1024, lr:1.0, w_d:0.001 => Score:-0.069794
[123/128]	Width:1024, lr:1.0, w_d:0.01 => Score:-0.069789
[124/128]	Width:1024, lr:1.0, w_d:0.1 => Score:-0.069779
[125/128]	Width:1024, lr:1.0, w_d:1.0 => Score:-0.069702
[126/128]	Width:1024, lr:1.0, w_d:10.0 => Score:-0.090039
[127/128]	Width:1024, lr:1.0, w_d:100.0 => Score:-0.182739
[128/128]	Width:1024, lr:1.0, w_d:0.0 => Score:-0.064323

Best validation score after 20 epochs: -0.050968. Best configuration:
Width:256, lr:1.0, w_d:0.0
preds_train_nn.shape == torch.Size([8000, 1]), preds_val_nn.shape == torch.Size([1000, 1]), preds_test_nn.shape == torch.Size([1000, 1])
score_train == -0.178517147898674, score_val == -0.007643047720193863, score_test == -0.007019739132374525
Best params for NTK: {'C': 10.0}
Best score for NTK: -0.14111847223216403
Best params for RBF: {'C': 100.0, 'gamma': 'scale'}
Best score for RBF: -0.1180881901565618
Best kernel: rbf
preds_train_km.shape == (8000,), preds_val_km.shape == (1000,), preds_test_km.shape == (1000,)
score_train == 0.005879654062050923, score_val == 0.03259184085905059, score_test == 0.038173461887724316
