{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "FACTOR = 1 / torch.sqrt(torch.tensor(N))\n",
    "K = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_1() -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns one sample of data from distribution D_A^(1)\n",
    "    \"\"\"\n",
    "    return torch.sign((torch.rand(N) * 2. - 1.)) * FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_2(imp_cols: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns one sample of data from distribution D_A^(2)\n",
    "\n",
    "    Arg:\n",
    "        imp_cols (torch.Tensor): Tensor of columns which are significant in the distribution\n",
    "    \"\"\"\n",
    "    x = torch.sign((torch.rand(N) * 2. - 1.)) * FACTOR\n",
    "    sign = torch.sign((torch.rand(1) * 2. - 1.))\n",
    "    for col in imp_cols:\n",
    "        x[col] = sign * FACTOR\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "\n",
    "A = choice(range(N), K, False)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_from_data(x: torch.Tensor, imp_cols: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns label y (0 or 1) given a single data point x\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Data tensor\n",
    "        imp_cols (torch.Tensor): Significant columns from the data\n",
    "    \"\"\"\n",
    "    y = torch.tensor(1.)\n",
    "    for col in imp_cols:\n",
    "        y *= torch.sign(x[col])\n",
    "    if y <= 0:\n",
    "        y = torch.tensor(0.)\n",
    "    return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_choices = torch.round(torch.rand(NUM_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.cat([generate_data_1().reshape(1, -1) if function_choices[i] == 0 else generate_data_2(A).reshape(1, -1) for i in range(NUM_SAMPLES)])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.cat([get_y_from_data(x, A).reshape(1, -1) for x in X])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, X_test, Y_training, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_training, Y_training, test_size=0.25)\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import make_dataloader\n",
    "\n",
    "train_dataloader, val_dataloader = make_dataloader(X_train, Y_train, batch_size=32, shuffle=True), make_dataloader(X_val, Y_val, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.models import SimpleNN\n",
    "from scripts.metrics import BinaryAccuracy\n",
    "from scripts.train import train_model\n",
    "from scripts.utils import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1, 2, 3, 4, 5]\n",
    "widths = [16, 32, 64]\n",
    "weight_decays = torch.logspace(-3, 3, 7)\n",
    "etas = [1e-4, 1e-3, 1e-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "best_depth = None\n",
    "best_width = None\n",
    "best_weight_decay = None\n",
    "best_eta = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = len(depths) * len(widths) * len(weight_decays) * len(etas)\n",
    "count = 0\n",
    "EPOCHS = 50\n",
    "\n",
    "print(f'Cross-validating across {total_count} models.\\n')\n",
    "\n",
    "for depth in depths:\n",
    "    for width in widths:\n",
    "        for weight_decay in weight_decays:\n",
    "            for eta in etas:\n",
    "                count += 1\n",
    "                model = SimpleNN(input_size=N, hidden_layers=depth, hidden_units=width).to(device)\n",
    "                loss_fn = torch.nn.BCELoss()\n",
    "                optimizer = torch.optim.Adam(params=model.parameters(), lr=eta, weight_decay=weight_decay)\n",
    "                metric = BinaryAccuracy()\n",
    "\n",
    "                history = train_model(\n",
    "                    model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    val_dataloader=val_dataloader,\n",
    "                    loss_fn=loss_fn,\n",
    "                    optimizer=optimizer,\n",
    "                    metric=metric,\n",
    "                    epochs=50,\n",
    "                    verbose=0,\n",
    "                    device=device\n",
    "                )\n",
    "                curr_score = history['val_score'][-1]\n",
    "\n",
    "                print(f'[{count}/{total_count}] depth={depth}, width={width}, lambda={weight_decay:.5f}, eta={eta} ===> validation score={curr_score:.6f}')\n",
    "                if curr_score > best_score:\n",
    "                    best_score = curr_score\n",
    "                    best_depth = depth\n",
    "                    best_width = width\n",
    "                    best_weight_decay = weight_decay\n",
    "                    best_eta = eta\n",
    "\n",
    "print(f'Validation complete. Best validation score after {EPOCHS} epochs = {best_score:.6f}')\n",
    "print(f'Best configuration: depth={best_depth}, width={best_width}, lambda={best_weight_decay:.5f}, eta={best_eta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_nn = SimpleNN(input_size=N, hidden_layers=best_depth, hidden_units=best_width).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(params=best_model_nn.parameters(), lr=best_eta, weight_decay=best_weight_decay)\n",
    "metric = BinaryAccuracy()\n",
    "early_stopper = EarlyStopping(patience=20, min_delta=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(\n",
    "    model=best_model_nn,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    metric=metric,\n",
    "    epochs=500,\n",
    "    early_stopping=early_stopper,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import plot_train_history\n",
    "\n",
    "plot_train_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.test import predict\n",
    "\n",
    "preds_train, preds_val = predict(best_model_nn, X_train, device), predict(best_model_nn, X_val, device)\n",
    "score_train, score_val = metric(preds_train, Y_train), metric(preds_val, Y_val)\n",
    "score_train, score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
